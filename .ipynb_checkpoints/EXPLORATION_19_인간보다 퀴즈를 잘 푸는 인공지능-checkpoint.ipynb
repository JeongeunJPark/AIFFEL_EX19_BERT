{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 이 노드의 루브릭"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. BERT pretrained model을 활용한 KorQuAD 모델이 정상적으로 학습되었다.    \n",
    ": KorQuAD 모델의 validation accuracy가 안정적으로 증가하였다.     \n",
    "\n",
    "#### 2. KorQuAD Inference 결과가 원래의 정답과 비교하여 유사하게 나오는 것을 확인하였다.      \n",
    ": 평가셋에 대해 모델 추론 결과와 실제 정답의 유사성이 확인되었다.    \n",
    "\n",
    "#### 3. Pretrained Model 활용이 효과적임을 실험을 통해 확인하였다.         \n",
    ": pretrained model을 사용하지 않았을 때 대비, 학습경과의 차이를 시각화를 통해 확인하였다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 목차"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 데이터 로드 및 데이터 전처리            \n",
    "\n",
    "### 2. Not-pretrained 학습 결과 확인하기\n",
    "\n",
    "### 3. Pretrained model 로딩하기     \n",
    "\n",
    "### 4. pretrained model finetune 하기      \n",
    "\n",
    "### 5. Inference 수행하기       \n",
    "\n",
    "### 6. 학습 경과 시각화 비교분석"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 데이터 로드 및 데이터 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "임포트 완료\n"
     ]
    }
   ],
   "source": [
    "#필요한 라이브러리 임포트\n",
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "import tensorflow_addons as tfa\n",
    "\n",
    "import os\n",
    "import re\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import pickle  \n",
    "import random\n",
    "\n",
    "import collections\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "import sentencepiece as spm\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "random_seed = 1234\n",
    "#랜덤 시드 배정\n",
    "random.seed(random_seed)\n",
    "\n",
    "np.random.seed(random_seed)\n",
    "tf.random.set_seed(random_seed)\n",
    "\n",
    "print('임포트 완료')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 오류가 생겨서 pip freeze로 버전을 확인하였다.                     \n",
    "- tensorflow와 tensorflow -addons의 버전은 각각 2.2.0, 0.12.1          \n",
    "- pip install tensorflow-addons==0.11.2로 다운그레이드                \n",
    "- [이 곳에서 tensorflow와 tensorflow-addons의 버전을 참고](https://stackoverflow.com/questions/65464463/importerror-cannot-import-name-keras-tensor-from-tensorflow-python-keras-eng)              "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 로드 및 내용 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "json data 프린트 함수 세팅\n"
     ]
    }
   ],
   "source": [
    "def print_json_tree(data, indent=\"\"):\n",
    "    for key, value in data.items():\n",
    "        if type(value) == list:     \n",
    "            print(f'{indent}- {key}: [{len(value)}]')\n",
    "            print_json_tree(value[0], indent + \"  \")\n",
    "        else:\n",
    "            print(f'{indent}- {key}: {value}')\n",
    "            \n",
    "print('json data 프린트 함수 세팅')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#데이터 패스 입력\n",
    "data_dir = os.getenv('HOME') + '/SUBMIT_MISSION_GIT/ex19_BERT/Data'\n",
    "model_dir =  os.getenv('HOME') + '/SUBMIT_MISSION_GIT/ex19_BERT/Model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- version: KorQuAD_v1.0_train\n",
      "- data: [1420]\n",
      "  - paragraphs: [3]\n",
      "    - qas: [8]\n",
      "      - answers: [1]\n",
      "        - text: 교향곡\n",
      "        - answer_start: 54\n",
      "      - id: 6566495-0-0\n",
      "      - question: 바그너는 괴테의 파우스트를 읽고 무엇을 쓰고자 했는가?\n",
      "    - context: 1839년 바그너는 괴테의 파우스트을 처음 읽고 그 내용에 마음이 끌려 이를 소재로 해서 하나의 교향곡을 쓰려는 뜻을 갖는다. 이 시기 바그너는 1838년에 빛 독촉으로 산전수전을 다 걲은 상황이라 좌절과 실망에 가득했으며 메피스토펠레스를 만나는 파우스트의 심경에 공감했다고 한다. 또한 파리에서 아브네크의 지휘로 파리 음악원 관현악단이 연주하는 베토벤의 교향곡 9번을 듣고 깊은 감명을 받았는데, 이것이 이듬해 1월에 파우스트의 서곡으로 쓰여진 이 작품에 조금이라도 영향을 끼쳤으리라는 것은 의심할 여지가 없다. 여기의 라단조 조성의 경우에도 그의 전기에 적혀 있는 것처럼 단순한 정신적 피로나 실의가 반영된 것이 아니라 베토벤의 합창교향곡 조성의 영향을 받은 것을 볼 수 있다. 그렇게 교향곡 작곡을 1839년부터 40년에 걸쳐 파리에서 착수했으나 1악장을 쓴 뒤에 중단했다. 또한 작품의 완성과 동시에 그는 이 서곡(1악장)을 파리 음악원의 연주회에서 연주할 파트보까지 준비하였으나, 실제로는 이루어지지는 않았다. 결국 초연은 4년 반이 지난 후에 드레스덴에서 연주되었고 재연도 이루어졌지만, 이후에 그대로 방치되고 말았다. 그 사이에 그는 리엔치와 방황하는 네덜란드인을 완성하고 탄호이저에도 착수하는 등 분주한 시간을 보냈는데, 그런 바쁜 생활이 이 곡을 잊게 한 것이 아닌가 하는 의견도 있다.\n",
      "  - title: 파우스트_서곡\n"
     ]
    }
   ],
   "source": [
    "#훈련 데이터 확인\n",
    "train_json_path = data_dir + '/KorQuAD_v1.0_train.json'\n",
    "\n",
    "with open(train_json_path) as f:\n",
    "    train_json = json.load(f)\n",
    "    print_json_tree(train_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- version: KorQuAD_v1.0_dev\n",
      "- data: [140]\n",
      "  - paragraphs: [2]\n",
      "    - qas: [7]\n",
      "      - answers: [1]\n",
      "        - text: 1989년 2월 15일\n",
      "        - answer_start: 0\n",
      "      - id: 6548850-0-0\n",
      "      - question: 임종석이 여의도 농민 폭력 시위를 주도한 혐의로 지명수배 된 날은?\n",
      "    - context: 1989년 2월 15일 여의도 농민 폭력 시위를 주도한 혐의(폭력행위등처벌에관한법률위반)으로 지명수배되었다. 1989년 3월 12일 서울지방검찰청 공안부는 임종석의 사전구속영장을 발부받았다. 같은 해 6월 30일 평양축전에 임수경을 대표로 파견하여 국가보안법위반 혐의가 추가되었다. 경찰은 12월 18일~20일 사이 서울 경희대학교에서 임종석이 성명 발표를 추진하고 있다는 첩보를 입수했고, 12월 18일 오전 7시 40분 경 가스총과 전자봉으로 무장한 특공조 및 대공과 직원 12명 등 22명의 사복 경찰을 승용차 8대에 나누어 경희대학교에 투입했다. 1989년 12월 18일 오전 8시 15분 경 서울청량리경찰서는 호위 학생 5명과 함께 경희대학교 학생회관 건물 계단을 내려오는 임종석을 발견, 검거해 구속을 집행했다. 임종석은 청량리경찰서에서 약 1시간 동안 조사를 받은 뒤 오전 9시 50분 경 서울 장안동의 서울지방경찰청 공안분실로 인계되었다.\n",
      "  - title: 임종석\n"
     ]
    }
   ],
   "source": [
    "#검증 데이터 확인\n",
    "vali_json_path = data_dir + '/KorQuAD_v1.0_dev.json'\n",
    "\n",
    "with open(vali_json_path) as f:\n",
    "    vali_json = json.load(f)\n",
    "    print_json_tree(vali_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"paragraphs\": [\n",
      "    {\n",
      "      \"qas\": [\n",
      "        {\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"교향곡\",\n",
      "              \"answer_start\": 54\n",
      "            }\n",
      "          ],\n",
      "          \"id\": \"6566495-0-0\",\n",
      "          \"question\": \"바그너는 괴테의 파우스트를 읽고 무엇을 쓰고자 했는가?\"\n",
      "        },\n",
      "        {\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"1악장\",\n",
      "              \"answer_start\": 421\n",
      "            }\n",
      "          ],\n",
      "          \"id\": \"6566495-0-1\",\n",
      "          \"question\": \"바그너는 교향곡 작곡을 어디까지 쓴 뒤에 중단했는가?\"\n",
      "        },\n",
      "        {\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"베토벤의 교향곡 9번\",\n",
      "              \"answer_start\": 194\n",
      "            }\n",
      "          ],\n",
      "          \"id\": \"6566495-0-2\",\n",
      "          \"question\": \"바그너가 파우스트 서곡을 쓸 때 어떤 곡의 영향을 받았는가?\"\n",
      "        },\n",
      "        {\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"파우스트\",\n",
      "              \"answer_start\": 15\n",
      "            }\n",
      "          ],\n",
      "          \"id\": \"6566518-0-0\",\n",
      "          \"question\": \"1839년 바그너가 교향곡의 소재로 쓰려고 했던 책은?\"\n",
      "        },\n",
      "        {\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"합창교향곡\",\n",
      "              \"answer_start\": 354\n",
      "            }\n",
      "          ],\n",
      "          \"id\": \"6566518-0-1\",\n",
      "          \"question\": \"파우스트 서곡의 라단조 조성이 영향을 받은 베토벤의 곡은?\"\n",
      "        },\n",
      "        {\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"1839\",\n",
      "              \"answer_start\": 0\n",
      "            }\n",
      "          ],\n",
      "          \"id\": \"5917067-0-0\",\n",
      "          \"question\": \"바그너가 파우스트를 처음으로 읽은 년도는?\"\n",
      "        },\n",
      "        {\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"파리\",\n",
      "              \"answer_start\": 410\n",
      "            }\n",
      "          ],\n",
      "          \"id\": \"5917067-0-1\",\n",
      "          \"question\": \"바그너가 처음 교향곡 작곡을 한 장소는?\"\n",
      "        },\n",
      "        {\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"드레스덴\",\n",
      "              \"answer_start\": 534\n",
      "            }\n",
      "          ],\n",
      "          \"id\": \"5917067-0-2\",\n",
      "          \"question\": \"바그너의 1악장의 초연은 어디서 연주되었는가?\"\n",
      "        }\n",
      "      ],\n",
      "      \"context\": \"1839년 바그너는 괴테의 파우스트을 처음 읽고 그 내용에 마음이 끌려 이를 소재로 해서 하나의 교향곡을 쓰려는 뜻을 갖는다. 이 시기 바그너는 1838년에 빛 독촉으로 산전수전을 다 걲은 상황이라 좌절과 실망에 가득했으며 메피스토펠레스를 만나는 파우스트의 심경에 공감했다고 한다. 또한 파리에서 아브네크의 지휘로 파리 음악원 관현악단이 연주하는 베토벤의 교향곡 9번을 듣고 깊은 감명을 받았는데, 이것이 이듬해 1월에 파우스트의 서곡으로 쓰여진 이 작품에 조금이라도 영향을 끼쳤으리라는 것은 의심할 여지가 없다. 여기의 라단조 조성의 경우에도 그의 전기에 적혀 있는 것처럼 단순한 정신적 피로나 실의가 반영된 것이 아니라 베토벤의 합창교향곡 조성의 영향을 받은 것을 볼 수 있다. 그렇게 교향곡 작곡을 1839년부터 40년에 걸쳐 파리에서 착수했으나 1악장을 쓴 뒤에 중단했다. 또한 작품의 완성과 동시에 그는 이 서곡(1악장)을 파리 음악원의 연주회에서 연주할 파트보까지 준비하였으나, 실제로는 이루어지지는 않았다. 결국 초연은 4년 반이 지난 후에 드레스덴에서 연주되었고 재연도 이루어졌지만, 이후에 그대로 방치되고 말았다. 그 사이에 그는 리엔치와 방황하는 네덜란드인을 완성하고 탄호이저에도 착수하는 등 분주한 시간을 보냈는데, 그런 바쁜 생활이 이 곡을 잊게 한 것이 아닌가 하는 의견도 있다.\"\n",
      "    },\n",
      "    {\n",
      "      \"qas\": [\n",
      "        {\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"한스 폰 뷜로\",\n",
      "              \"answer_start\": 402\n",
      "            }\n",
      "          ],\n",
      "          \"id\": \"6566495-1-0\",\n",
      "          \"question\": \"바그너의 작품을 시인의 피로 쓰여졌다고 극찬한 것은 누구인가?\"\n",
      "        },\n",
      "        {\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"리스트\",\n",
      "              \"answer_start\": 23\n",
      "            }\n",
      "          ],\n",
      "          \"id\": \"6566495-1-1\",\n",
      "          \"question\": \"잊혀져 있는 파우스트 서곡 1악장을 부활시킨 것은 누구인가?\"\n",
      "        },\n",
      "        {\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"20루이의 금\",\n",
      "              \"answer_start\": 345\n",
      "            }\n",
      "          ],\n",
      "          \"id\": \"6566495-1-2\",\n",
      "          \"question\": \"바그너는 다시 개정된 총보를 얼마를 받고 팔았는가?\"\n",
      "        },\n",
      "        {\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"리스트\",\n",
      "              \"answer_start\": 23\n",
      "            }\n",
      "          ],\n",
      "          \"id\": \"6566518-1-0\",\n",
      "          \"question\": \"파우스트 교향곡을 부활시킨 사람은?\"\n",
      "        },\n",
      "        {\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"한스 폰 뷜로\",\n",
      "              \"answer_start\": 402\n",
      "            }\n",
      "          ],\n",
      "          \"id\": \"6566518-1-1\",\n",
      "          \"question\": \"파우스트 교향곡을 피아노 독주용으로 편곡한 사람은?\"\n",
      "        },\n",
      "        {\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"리스트\",\n",
      "              \"answer_start\": 23\n",
      "            }\n",
      "          ],\n",
      "          \"id\": \"5917067-1-0\",\n",
      "          \"question\": \"1악장을 부활시켜 연주한 사람은?\"\n",
      "        },\n",
      "        {\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"한스 폰 뷜로\",\n",
      "              \"answer_start\": 402\n",
      "            }\n",
      "          ],\n",
      "          \"id\": \"5917067-1-1\",\n",
      "          \"question\": \"파우스트 교향곡에 감탄하여 피아노곡으로 편곡한 사람은?\"\n",
      "        },\n",
      "        {\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"1840년\",\n",
      "              \"answer_start\": 3\n",
      "            }\n",
      "          ],\n",
      "          \"id\": \"5917067-1-2\",\n",
      "          \"question\": \"리스트가 바그너와 알게 된 연도는?\"\n",
      "        }\n",
      "      ],\n",
      "      \"context\": \"한편 1840년부터 바그너와 알고 지내던 리스트가 잊혀져 있던 1악장을 부활시켜 1852년에 바이마르에서 연주했다. 이것을 계기로 바그너도 이 작품에 다시 관심을 갖게 되었고, 그 해 9월에는 총보의 반환을 요구하여 이를 서곡으로 간추린 다음 수정을 했고 브라이트코프흐 & 헤르텔 출판사에서 출판할 개정판도 준비했다. 1853년 5월에는 리스트가 이 작품이 수정되었다는 것을 인정했지만, 끝내 바그너의 출판 계획은 무산되고 말았다. 이후 1855년에 리스트가 자신의 작품 파우스트 교향곡을 거의 완성하여 그 사실을 바그너에게 알렸고, 바그너는 다시 개정된 총보를 리스트에게 보내고 브라이트코프흐 & 헤르텔 출판사에는 20루이의 금을 받고 팔았다. 또한 그의 작품을 “하나하나의 음표가 시인의 피로 쓰여졌다”며 극찬했던 한스 폰 뷜로가 그것을 피아노 독주용으로 편곡했는데, 리스트는 그것을 약간 변형되었을 뿐이라고 지적했다. 이 서곡의 총보 첫머리에는 파우스트 1부의 내용 중 한 구절을 인용하고 있다.\"\n",
      "    },\n",
      "    {\n",
      "      \"qas\": [\n",
      "        {\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"주제, 동기\",\n",
      "              \"answer_start\": 70\n",
      "            }\n",
      "          ],\n",
      "          \"id\": \"6566495-2-0\",\n",
      "          \"question\": \"서주에는 무엇이 암시되어 있는가?\"\n",
      "        },\n",
      "        {\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"제1바이올린\",\n",
      "              \"answer_start\": 148\n",
      "            }\n",
      "          ],\n",
      "          \"id\": \"6566495-2-1\",\n",
      "          \"question\": \"첫부분에는 어떤 악기를 사용해 더욱 명확하게 나타내는가?\"\n",
      "        },\n",
      "        {\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"소나타 형식\",\n",
      "              \"answer_start\": 272\n",
      "            }\n",
      "          ],\n",
      "          \"id\": \"6566495-2-2\",\n",
      "          \"question\": \"주요부는 어떤 형식으로 되어 있는가?\"\n",
      "        },\n",
      "        {\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"저음 주제\",\n",
      "              \"answer_start\": 102\n",
      "            }\n",
      "          ],\n",
      "          \"id\": \"6566518-2-0\",\n",
      "          \"question\": \"첫 부분의 주요주제를 암시하는 주제는?\"\n",
      "        },\n",
      "        {\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"D장조\",\n",
      "              \"answer_start\": 409\n",
      "            }\n",
      "          ],\n",
      "          \"id\": \"6566518-2-1\",\n",
      "          \"question\": \"제2주제의 축소된 재현부의 조성은?\"\n",
      "        },\n",
      "        {\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"4/4박자\",\n",
      "              \"answer_start\": 35\n",
      "            }\n",
      "          ],\n",
      "          \"id\": \"5917067-2-0\",\n",
      "          \"question\": \"곡이 시작할때의 박자는?\"\n",
      "        },\n",
      "        {\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"고뇌와 갈망 동기, 청춘의 사랑 동기\",\n",
      "              \"answer_start\": 115\n",
      "            }\n",
      "          ],\n",
      "          \"id\": \"5917067-2-1\",\n",
      "          \"question\": \"이 곡의 주요 주제는?\"\n",
      "        },\n",
      "        {\n",
      "          \"answers\": [\n",
      "            {\n",
      "              \"text\": \"D장조\",\n",
      "              \"answer_start\": 409\n",
      "            }\n",
      "          ],\n",
      "          \"id\": \"5917067-2-2\",\n",
      "          \"question\": \"제 2주제에선 무슨 장조로 재현되는가?\"\n",
      "        }\n",
      "      ],\n",
      "      \"context\": \"이 작품은 라단조, Sehr gehalten(아주 신중하게), 4/4박자의 부드러운 서주로 서주로 시작되는데, 여기에는 주요 주제, 동기의 대부분이 암시, 예고되어 있다. 첫 부분의 저음 주제는 주요 주제(고뇌와 갈망 동기, 청춘의 사랑 동기)를 암시하고 있으며, 제1바이올린으로 더욱 명확하게 나타난다. 또한 그것을 이어받는 동기도 중요한 역할을 한다. 여기에 새로운 소재가 더해진 뒤에 새로운 주제도 연주된다. 주요부는 Sehr bewegt(아주 격동적으로), 2/2박자의 자유로운 소나타 형식으로 매우 드라마틱한 구상과 유기적인 구성을 하고 있다. 여기에는 지금까지의 주제나 소재 외에도 오보에에 의한 선율과 제2주제를 떠올리게 하는 부차적인 주제가 더해지는데, 중간부에서는 약보3이 중심이 되고 제2주제는 축소된 재현부에서 D장조로 재현된다. 마지막에는 주요 주제를 회상하면서 조용히 마친다.\"\n",
      "    }\n",
      "  ],\n",
      "  \"title\": \"파우스트_서곡\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "#Json의 실제 데이터를 json.dumps()로 확인해보기!\n",
    "\n",
    "print(json.dumps(train_json[\"data\"][0], indent=2, ensure_ascii=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터 전처리        \n",
    "\n",
    "## 1. 띄어쓰기 단위 정보 관리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_whitespace(c):\n",
    "    if c == \" \" or c == \"\\t\" or c == \"\\r\" or c == \"\\n\" or ord(c) == 0x202F:\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#공백을 기준으로 토큰화를 수행하는 함수 정의\n",
    "\n",
    "def _tokenize_whitespace(string):\n",
    "    word_tokens=[]\n",
    "    char_to_word=[]\n",
    "    prev_is_whitespace=True\n",
    "    \n",
    "    for c in string:\n",
    "        if is_whitespace(c):\n",
    "            prev_is_whitespace = True\n",
    "            \n",
    "        else:\n",
    "            #이전이 공백이라면 새로운 워드 토큰으로 분류\n",
    "            if prev_is_whitespace:\n",
    "                word_tokens.append(c)\n",
    "            else:\n",
    "            #이전이 공백이 아니라면 같은 워드 토큰으로 분류\n",
    "                word_tokens[-1] += c\n",
    "                \n",
    "            #분류를 끝내고 이전공백=False\n",
    "            prev_is_whitespace = False\n",
    "            \n",
    "        #전체 char_to_word에 append\n",
    "        char_to_word.append(len(word_tokens)-1)\n",
    "        \n",
    "    return word_tokens, char_to_word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 형태소 단위 토큰화"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 한국어의 경우, 동사의 활용형이 지나치게 많기 때문에 같은 형태소를 공유하는 다양한 어미를 모두 다른 워드벡터로 분류하면 차원 수가 엄청나게 늘어나게 된다.      \n",
    "- 이를 방지하기 위해 __Subword Segmentation__ 을 활용한다.     \n",
    "- SentencePiece 모델을 활용한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Vocab 모델 로드\n",
    "vocab = spm.SentencePieceProcessor()\n",
    "vocab.load(f\"{model_dir}/ko_32000.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#형태소 단위 토큰화 함수 세팅\n",
    "def _tokenize_vocab(vocab, context_words):\n",
    "    #각 단위의 길이\n",
    "    word_to_token=[]\n",
    "    #형태소 단위로 분리된 단어\n",
    "    context_tokens=[]\n",
    "    \n",
    "    for (i, word) in enumerat다e(context_words):\n",
    "        word_to_token.append(len(context_tokens))\n",
    "        \n",
    "        #형태소 단위 토큰을 분리의\n",
    "        tokens = vocab.encode_as_pieces(word)\n",
    "        \n",
    "        for token in tokens:\n",
    "            context_tokens.append(token)\n",
    "            \n",
    "    return context_tokens, word_to_token"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__함수세팅 검증__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "string1 = '1839년 파우스트을 읽었다.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['1839년', '파우스트을', '읽었다.'], [0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_tokenize_whitespace(string1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Improve Span     \n",
    "\n",
    "- KorQuAD에서 질문(Question), 지문(Context), 정답(Answer)을 찾아내 본다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#json의 파일 구조를 기반으로 질문, 지문, 정답을 추출해본다.\n",
    "\n",
    "context = train_json['data'][0]['paragraphs'][0]['context']\n",
    "question = train_json['data'][0]['paragraphs'][0]['qas'][0]['question']\n",
    "answer_text = train_json['data'][0]['paragraphs'][0]['qas'][0]['answers'][0]['text']\n",
    "answer_start = train_json['data'][0]['paragraphs'][0]['qas'][0]['answers'][0]['answer_start']\n",
    "answer_end = answer_start + len(answer_text) -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[context]  1839년 바그너는 괴테의 파우스트을 처음 읽고 그 내용에 마음이 끌려 이를 소재로 해서 하나의 교향곡을 쓰려는 뜻을 갖는다. 이 시기 바그너는 1838년에 빛 독촉으로 산전수전을 다 걲은 상황이라 좌절과 실망에 가득했으며 메피스토펠레스를 만나는 파우스트의 심경에 공감했다고 한다. 또한 파리에서 아브네크의 지휘로 파리 음악원 관현악단이 연주하는 베토벤의 교향곡 9번을 듣고 깊은 감명을 받았는데, 이것이 이듬해 1월에 파우스트의 서곡으로 쓰여진 이 작품에 조금이라도 영향을 끼쳤으리라는 것은 의심할 여지가 없다. 여기의 라단조 조성의 경우에도 그의 전기에 적혀 있는 것처럼 단순한 정신적 피로나 실의가 반영된 것이 아니라 베토벤의 합창교향곡 조성의 영향을 받은 것을 볼 수 있다. 그렇게 교향곡 작곡을 1839년부터 40년에 걸쳐 파리에서 착수했으나 1악장을 쓴 뒤에 중단했다. 또한 작품의 완성과 동시에 그는 이 서곡(1악장)을 파리 음악원의 연주회에서 연주할 파트보까지 준비하였으나, 실제로는 이루어지지는 않았다. 결국 초연은 4년 반이 지난 후에 드레스덴에서 연주되었고 재연도 이루어졌지만, 이후에 그대로 방치되고 말았다. 그 사이에 그는 리엔치와 방황하는 네덜란드인을 완성하고 탄호이저에도 착수하는 등 분주한 시간을 보냈는데, 그런 바쁜 생활이 이 곡을 잊게 한 것이 아닌가 하는 의견도 있다.\n",
      "[question]  바그너는 괴테의 파우스트를 읽고 무엇을 쓰고자 했는가?\n",
      "[answer]  교향곡\n",
      "[answer_start] index:  54 character:  교\n",
      "[answer_end]index:  56 character:  곡\n"
     ]
    }
   ],
   "source": [
    "#프린트로 검증\n",
    "print('[context] ', context)\n",
    "print('[question] ', question)\n",
    "print('[answer] ', answer_text)\n",
    "print('[answer_start] index: ', answer_start, 'character: ', context[answer_start])\n",
    "print('[answer_end]index: ', answer_end, 'character: ', context[answer_end])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 위의 1.띄어쓰기 단위 토큰화, 2.형태소 단위 토큰화를 콘텍스트에 적용해본다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "콘텍스트를 띄어쓰기 단위 토큰화 ['1839년', '바그너는', '괴테의', '파우스트을', '처음', '읽고', '그', '내용에', '마음이', '끌려', '이를', '소재로', '해서', '하나의', '교향곡을', '쓰려는', '뜻을', '갖는다.', '이', '시기']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 2, 2, 2, 2, 3, 3, 3, 3, 3],\n",
       " '1839년 바그너는 괴테의 파우스트을')"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_tokens, char_to_word = _tokenize_whitespace(context)\n",
    "\n",
    "print('콘텍스트를 띄어쓰기 단위 토큰화', word_tokens[:20])\n",
    "\n",
    "char_to_word[:20], context[:20]데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 ['▁1839', '년']\n",
      "2 ['▁바그너', '는']\n",
      "4 ['▁괴테', '의']\n",
      "6 ['▁', '파우스트', '을']\n",
      "9 ['▁처음']\n",
      "10 ['▁읽고']\n",
      "11 ['▁그']\n",
      "12 ['▁내용에']\n",
      "13 ['▁마음이']\n",
      "14 ['▁끌려']\n",
      "15 ['▁이를']\n",
      "16 ['▁소재로']\n",
      "17 ['▁해서']\n",
      "18 ['▁하나의']\n",
      "19 ['▁교향곡', '을']\n",
      "21 ['▁쓰', '려는']\n",
      "23 ['▁뜻을']\n",
      "24 ['▁갖는다', '.']\n",
      "26 ['▁이']\n",
      "27 ['▁시기']\n"
     ]
    }
   ],
   "source": [
    "context_tokens, word_to_token = _tokenize_vocab(vocab, word_tokens)\n",
    "\n",
    "for i in range(min(20, len(word_to_token)-1)):\n",
    "    print(word_to_token[i], context_tokens[word_to_token[i] :word_to_token[i+1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 여기서, 정답 글자의 시작 인덱스와 끝 인덱스를 띄어쓰기 단위로 변환하면 어떻게 될까?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word_start/ word_end/ answer_text/ word_tokens[word_start:word_end+1]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(14, 14, '교향곡', ['교향곡을'])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#answer_start와 answer_end로 부터 word_start와 word_end를 구한다.\n",
    "\n",
    "word_start = char_to_word[answer_start]\n",
    "word_end = char_to_word[answer_end]\n",
    "\n",
    "print('word_start/', 'word_end/', 'answer_text/', 'w데이터ord_tokens[word_start:word_end+1]')\n",
    "word_start, word_end, answer_text, word_tokens[word_start:word_end+1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 답은 14번째에 있음을 인덱스로는 찾았으나, 띄어쓰기로 찾았을 때 '교향곡을' 로 찾게 된다.        \n",
    "> __이를 수정하기 위해 word_start~word_end 까지를 형태소 단위로 찾아보자__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token_start/ token_end/ context_tokens[token_start:token_end+1]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(19, 20, ['▁교향곡', '을'])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_start = word_to_token[word_start]\n",
    "\n",
    "if word_end < len(word_to_token)-1:\n",
    "    token_end = word_to_token[word_end+1]-1\n",
    "else:\n",
    "    token_end = len(context_tokens)-1\n",
    "    \n",
    "print('token_start/', 'token_end/', 'context_tokens[token_start:token_end+1]')\n",
    "token_start, token_end, context_tokens[token_start:token_end+1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - 정답만 쏙! 빼오기 위해 __answer_text를 형태소 단위로 토큰화__ 해둔다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'▁교향곡'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_answer = \" \".join(vocab.encode_as_pieces(answer_text))\n",
    "\n",
    "token_answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Context에서 answer의 위치를 subword상태에서 토큰화된 상태에서 찾는 함수를 세팅"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _improve_span(vocab, context_tokens, token_start, token_end, char_answer):\n",
    "    \n",
    "    #char_answer를 넣고 형태소 단위로 토큰화된 걔를 얻는다!\n",
    "    token_answer = \" \".join(vocab.encode_as_pieces(char_answer))\n",
    "    \n",
    "    for new_start in range(token_start, token_end+1):\n",
    "        for new_end in range(token_end, new_start-1, -1):\n",
    "            text_span = \" \".join(context_tokens[new_start : (new_end)+1])\n",
    "            \n",
    "            #답안이 이미 형태소 단위 토큰화와 일치할 때\n",
    "            if text_span == token_answer:\n",
    "                return (new_start, new_end)\n",
    "            \n",
    "    return (token_start, token_end)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.데이터셋 분리 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- train 데이터셋, validation 데이터셋을 분리하고     \n",
    "- improve_span 함수를 통해 최종적으로 전처리한 후      \n",
    "- 파일로 저장합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최종 전처리 및 파일 저장 함수 세팅\n"
     ]
    }
   ],
   "source": [
    "def dump_korquad(vocab, json_data, out_file):\n",
    "    #우선 쓰기전용으로 파일을 데려와\n",
    "    with open(out_file, \"w\") as f:\n",
    "        \n",
    "        #이름은 title 컬럼으로 붙여주고.\n",
    "        for data in tqdm(json_data[\"data\"]):\n",
    "            title = data['title']\n",
    "        \n",
    "            #패러그래프를 가져와서, 띄어쓰기 단위로 분절\n",
    "            for paragraph in data[\"paragraphs\"]:\n",
    "                context = paragraph[\"context\"]\n",
    "                context_words, char_to_word = _tokenize_whitespace(context)\n",
    "                \n",
    "                for qa in paragraph[\"qas\"]:\n",
    "                    \n",
    "                    #만약 정답의 길이가 1이라면(더 자르고 말고 할 게 없는 상태)\n",
    "                    #빠져나가도록 assert\n",
    "                    assert len(qa[\"answers\"]) == 1\n",
    "                    \n",
    "                    qa_id = qa[\"id\"]\n",
    "                    question = qa[\"question\"]데이터\n",
    "                    \n",
    "                    answer_text = qa[\"answers\"][0][\"text\"]\n",
    "                    answer_start = qa[\"answers\"][0][\"answer_start\"]\n",
    "                    answer_end = answer_start + len(answer_text) - 1\n",
    "                    \n",
    "                    #만약 데이터 안의 정답과, 분리한 context 안의 정답이 같다면(정리할 게 없다면)\n",
    "                    #빠져나가도록 assert 처리\n",
    "                    assert answer_text == context[answer_start:answer_end + 1]\n",
    "                    \n",
    "                    #워드 스타트 = 정답 시작점\n",
    "                    word_start = char_to_word[answer_start]\n",
    "                    word_end = char_to_word[answer_end]\n",
    "                    \n",
    "                    word_answer = \" \".join(context_words[word_start:word_end +데이터 1])\n",
    "                    char_answer = \" \".join(answer_text.strip().split())\n",
    "                    \n",
    "                    #이미 char_answer이 word_answer안에 있어서 처리할 필요 없다면\n",
    "                    #빠져나가도록 assert 처리\n",
    "                    assert char_answer in word_answer\n",
    "                    \n",
    "                    context_tokens, word_to_token = _tokenize_vocab(vocab, context_words)\n",
    "                    \n",
    "                    token_start = word_to_token[word_start]\n",
    "                    if word_end < len(word_to_token) - 1:\n",
    "                        token_end = word_to_token[word_end + 1] - 1\n",
    "                    else:\n",
    "                        token_end = len(context_tokens) - 1\n",
    "\n",
    "                    token_start, token_end = _improve_span(vocab, context_tokens, token_start, token_end, char_answer)\n",
    "\n",
    "                    data = {\"qa_id\": qa_id, \"title\": title, \"question\": vocab.encode_as_pieces(question), \"context\": context_tokens, \"answer\": char_answer, \"token_start\": token_start, \"token_end\":token_end}\n",
    "                    f.write(json.dumps(data, ensure_ascii=False))\n",
    "                    f.write(\"\\n\")\n",
    "                    \n",
    "print('최종 전처리 및 파일 저장 함수 세팅')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ba96d583a3245ca829e5d1ea9331790",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1420 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3ed7fea9aca4c738e4671f90e49adc1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/140 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dump_korquad(vocab, train_json, f\"{data_dir}/korquad_train.json\")\n",
    "dump_korquad(vocab, vali_json, f\"{data_dir}/korquad_dev.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#최종 전처리가 잘 되었는지 확인해보자구!\n",
    "def print_file(filename, count=10):\n",
    "    \"\"\"\n",
    "    파일 내용 출력\n",
    "    :param filename: 파일 이름\n",
    "    :param count: 출력 라인 수\n",
    "    \"\"\"\n",
    "    with open(filename) as f:\n",
    "        for i, line in enumerate(f):\n",
    "            if count <= i:\n",
    "                break\n",
    "            print(line.strip())\n",
    "\n",
    "print_file(f\"{data_dir}/korquad_train.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 데이터셋 로드"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 지금까지 만든 데이터셋을 메모리에 로드한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_json = os.path.join(data_dir, \"korquad_train.json\")\n",
    "vali_json = os.path.join(data_dir, \"korquad_dev.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config(dict):\n",
    "    __getattr__ = dict.__getitem__\n",
    "    __setattr__ = dict.__setitem__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = Config({\n",
    "    'max_seq_length': 384,\n",
    "    'max_query_length': 64,\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_seq_length': 384, 'max_query_length': 64}"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 생성한 데이터셋 파일을 메모리에 로딩한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "#max길이와 max쿼리를 정하기 위해, 위의 config를 세팅하여 지정해주었다.\n",
    "#이를 토대로 파일을 메모리에 로딩하는 함수를 정의하였다.\n",
    "def load_data(args, filename):\n",
    "    \n",
    "    inputs, segments, labels_start, labels_end = [], [], [], []\n",
    "\n",
    "    n_discard = 0\n",
    "    with open(filename, \"r\") as f:\n",
    "        for i, line in enumerate(tqdm(f, desc=f\"Loading ...\")):\n",
    "            data = json.loads(line)\n",
    "            token_start = data.get(\"token_start\")\n",
    "            token_end = data.get(\"token_end\")\n",
    "            question = data[\"question\"][:args.max_query_length]\n",
    "            context = data[\"context\"]\n",
    "            answer_tokens = \" \".join(context[token_start:token_end + 1])\n",
    "            context_len = args.max_seq_length - len(question) - 3\n",
    "\n",
    "            if token_end >= context_len:\n",
    "                # 최대 길이내에 token이 들어가지 않은 경우 처리하지 않음\n",
    "                n_discard += 1\n",
    "                continue\n",
    "            context = context[:context_len]\n",
    "            assert len(question) + len(context) <= args.max_seq_length - 3\n",
    "\n",
    "            tokens = ['[CLS]'] + question + ['[SEP]'] + context + ['[SEP]']\n",
    "            ids = [vocab.piece_to_id(token) for token in tokens]\n",
    "            ids += [0] * (args.max_seq_length - len(ids))\n",
    "            inputs.append(ids)\n",
    "            segs = [0] * (len(question) + 2) + [1] * (len(context) + 1)\n",
    "            segs += [0] * (args.max_seq_length - len(segs))\n",
    "            segments.append(segs)\n",
    "            token_start += (len(question) + 2)\n",
    "            labels_start.append(token_start)\n",
    "            token_end += (len(question) + 2)\n",
    "            labels_end.append(token_end)\n",
    "    print(f'n_discard: {n_discard}')\n",
    "\n",
    "    return (np.array(inputs), np.array(segments)), (np.array(labels_start), np.array(labels_end))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbc0065ca33f4fbc974351edb2289614",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading ...: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_discard: 430\n",
      "train_inputs: (59977, 384)\n",
      "train_inputs: (59977, 384)\n",
      "train_labels: (59977,)\n",
      "train_labels: (59977,)\n"
     ]
    }
   ],
   "source": [
    "# 학습 데이터의 인풋, 라벨을 로드한다.\n",
    "train_inputs, train_labels = load_data(args, train_json)\n",
    "print(f\"train_inputs: {train_inputs[0].shape}\")\n",
    "print(f\"train_inputs: {train_inputs[1].shape}\")\n",
    "print(f\"train_labels: {train_labels[0].shape}\")\n",
    "print(f\"train_labels: {train_labels[1].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a18f84994324495825e455945cff45d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading ...: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_discard: 78\n",
      "dev_inputs: (5696, 384)\n",
      "dev_inputs: (5696, 384)\n",
      "dev_labels: (5696,)\n",
      "dev_labels: (5696,)\n"
     ]
    }
   ],
   "source": [
    "# 검증 데이터의 인풋, 라벨을 로드한다.\n",
    "vali_inputs, vali_labels = load_data(args, vali_json)\n",
    "print(f\"dev_inputs: {vali_inputs[0].shape}\")\n",
    "print(f\"dev_inputs: {vali_inputs[1].shape}\")\n",
    "print(f\"dev_labels: {vali_labels[0].shape}\")\n",
    "print(f\"dev_labels: {vali_labels[1].shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 데이터셋 확인!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([    5, 15798,    10, 28935,     9,    11, 29566,    20, 14604,\n",
       "       20424,  3904,    70,    11,  4648,    10,    19,  1910,     4,\n",
       "       22070,    15, 15798,    10, 28935,     9,    11, 29566,    16,\n",
       "         626, 14604,    38, 14028, 11773, 13829,   384,  8376,  3021,\n",
       "        1239,  6874,    16,  1687,  5958,  2694,  5061,     7,    30,\n",
       "        1613, 15798,    10, 28065,    75,  4415,  1816,  4978,    27,\n",
       "         347,   145,   107,  2703,   263,    11,     1,    18,  5853,\n",
       "          99,  9677,    24, 11969,    13,  7595,   437,  1019,  5907,\n",
       "         257,  3794,  1972,    20, 11278,    11, 29566,     9,   612,\n",
       "       12631, 13214,  1732,    76,     7,   110,  8802, 17581,   354,\n",
       "        9648,  2060,    21,  1682, 22110, 18164,    17, 21076, 14980,\n",
       "           9,  6874,    81, 11325,  4239,  3597,  1010,  1035, 17670,\n",
       "           8,  2447,  1306,    35,   443,    11, 29566,     9,   315,\n",
       "       12729, 14457,    30,  7938,  3742, 10766,   634,  9971, 17590,\n",
       "       19424,    10,   285,  4080,    61, 17573,   483,     7,  7588,\n",
       "           9,   473,   338,   147,  1924,     9, 11016,   136,  1034,\n",
       "          13, 11672,    40,  3436,  5217,  7898, 11684,    57,   830,\n",
       "           9,    19,  3319,    86,   220,   464, 14980,     9, 20515,\n",
       "         412,   991,   684,  1924,     9,   634,   920,   144,   430,\n",
       "          34,    25,     7,  4210,  6874,  2150,    16, 22070,   298,\n",
       "        1159,    75,  1098,  8802,  7490,   805,    35, 18678,    16,\n",
       "        1657,  1970,  2272,    53,     7,   110,  6559,  2178,    24,\n",
       "         756,    82,    30,   315,   684,  3772, 18678,    12,    16,\n",
       "        1682, 22110,     9, 22469,    22,  1757,    61,  8817,   194,\n",
       "         164,  1693,   749,     8,  6739, 12202,    10,   494,     7,\n",
       "         502, 12181,    18,    46,    15,   374,    17,  1680,   708,\n",
       "       26344,    22,  1757,   432,   465,   351,    32, 18563,   710,\n",
       "           8,  2585,  1384, 16071,   265,  3360,     7,    38,   747,\n",
       "          82,   383,   678,   200,    26,   590,  1281,    41,  1172,\n",
       "          31,    16,  2178,    43,  3044,   156,    17,   647,   468,\n",
       "        7490,    41,    84,   758,    92,    33,  3401,   369, 18319,\n",
       "           8,  2582, 29798,  1102,    17,    30,  4573, 11170,   139,\n",
       "          58,   220,   773,    19,   211, 23824,    25,     7,     4,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Question과 Context가 포함된 입력데이터 1번째\n",
    "train_inputs[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Question을 0으로, Context를 1로 구분해 준 Segment 데이터 1번째\n",
    "train_inputs[1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(37, 37)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Answer위치의 시작점과 끝점 라벨 1번째\n",
    "train_labels[0][0], train_labels[1][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. BERT 모델을 활용한 도전"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BERT 모델을 구성하는 함수 및 레이어 세팅하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 유틸리티 함수들\n",
    "\n",
    "def get_pad_mask(tokens, i_pad=0):\n",
    "    mask = tf.cast(tf.math.equal(tokens, i_pad), tf.float32)\n",
    "    mask = tf.expand_dims(mask, axis=1)\n",
    "    return mask\n",
    "\n",
    "\n",
    "def get_ahead_mask(tokens, i_pad=0):\n",
    "    n_seq = tf.shape(tokens)[1]\n",
    "    ahead_mask = 1 - tf.linalg.band_part(tf.ones((n_seq, n_seq)), -1, 0)\n",
    "    ahead_mask = tf.expand_dims(ahead_mask, axis=0)\n",
    "    pad_mask = get_pad_mask(tokens, i_pad)\n",
    "    mask = tf.maximum(ahead_mask, pad_mask)\n",
    "    return mask\n",
    "\n",
    "\n",
    "@tf.function(experimental_relax_shapes=True)\n",
    "def gelu(x):\n",
    "    return 0.5 * x * (1 + K.tanh(x * 0.7978845608 * (1 + 0.044715 * x * x)))\n",
    "\n",
    "\n",
    "def kernel_initializer(stddev=0.02):\n",
    "    return tf.keras.initializers.TruncatedNormal(stddev=stddev)\n",
    "\n",
    "\n",
    "def bias_initializer():\n",
    "    return tf.zeros_initializer\n",
    "\n",
    "\n",
    "class Config(dict):\n",
    "    __getattr__ = dict.__getitem__\n",
    "    __setattr__ = dict.__setitem__\n",
    "\n",
    "    @classmethod\n",
    "    def load(cls, file):\n",
    "        with open(file, 'r') as f:\n",
    "            config = json.loads(f.read())\n",
    "            return Config(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mode == \"embedding\" 일 경우 Token Embedding Layer 로 사용되는 layer 클래스입니다. \n",
    "class SharedEmbedding(tf.keras.layers.Layer):\n",
    "    def __init__(self, config, name=\"weight_shared_embedding\"):\n",
    "        super().__init__(name=name)\n",
    "\n",
    "        self.n_vocab = config.n_vocab\n",
    "        self.d_model = config.d_model\n",
    "    \n",
    "    def build(self, input_shape):\n",
    "        with tf.name_scope(\"shared_embedding_weight\"):\n",
    "            self.shared_weights = self.add_weight(\n",
    "                \"weights\",\n",
    "                shape=[self.n_vocab, self.d_model],\n",
    "                initializer=kernel_initializer()\n",
    "            )\n",
    "\n",
    "    def call(self, inputs, mode=\"embedding\"):\n",
    "        # mode가 embedding일 경우 embedding lookup 실행\n",
    "        if mode == \"embedding\":\n",
    "            return self._embedding(inputs)\n",
    "        # mode가 linear일 경우 linear 실행\n",
    "        elif mode == \"linear\":\n",
    "            return self._linear(inputs)\n",
    "        # mode가 기타일 경우 오류 발생\n",
    "        else:\n",
    "            raise ValueError(f\"mode {mode} is not valid.\")\n",
    "    \n",
    "    def _embedding(self, inputs):\n",
    "        embed = tf.gather(self.shared_weights, tf.cast(inputs, tf.int32))\n",
    "        return embed\n",
    "\n",
    "    def _linear(self, inputs):  # (bs, n_seq, d_model)\n",
    "        n_batch = tf.shape(inputs)[0]\n",
    "        n_seq = tf.shape(inputs)[1]\n",
    "        inputs = tf.reshape(inputs, [-1, self.d_model])  # (bs * n_seq, d_model)\n",
    "        outputs = tf.matmul(inputs, self.shared_weights, transpose_b=True)\n",
    "        outputs = tf.reshape(outputs, [n_batch, n_seq, self.n_vocab])  # (bs, n_seq, n_vocab)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEmbedding(tf.keras.layers.Layer):\n",
    "    def __init__(self, config, name=\"position_embedding\"):\n",
    "        super().__init__(name=name)\n",
    "        \n",
    "        self.embedding = tf.keras.layers.Embedding(config.n_seq, config.d_model, embeddings_initializer=kernel_initializer())\n",
    "\n",
    "    def call(self, inputs):\n",
    "        position = tf.cast(tf.math.cumsum(tf.ones_like(inputs), axis=1, exclusive=True), tf.int32)\n",
    "        embed = self.embedding(position)\n",
    "        return embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScaleDotProductAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, name=\"scale_dot_product_attention\"):\n",
    "        \n",
    "        super().__init__(name=name)\n",
    "\n",
    "    def call(self, Q, K, V, attn_mask):\n",
    "        attn_score = tf.matmul(Q, K, transpose_b=True)\n",
    "        scale = tf.math.sqrt(tf.cast(tf.shape(K)[-1], tf.float32))\n",
    "        attn_scale = tf.math.divide(attn_score, scale)\n",
    "        attn_scale -= 1.e9 * attn_mask\n",
    "        attn_prob = tf.nn.softmax(attn_scale, axis=-1)\n",
    "        attn_out = tf.matmul(attn_prob, V)\n",
    "        return attn_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, config, name=\"multi_head_attention\"):\n",
    "        \n",
    "        super().__init__(name=name)\n",
    "\n",
    "        self.d_model = config.d_model\n",
    "        self.n_head = config.n_head\n",
    "        self.d_head = config.d_head\n",
    "\n",
    "        # Q, K, V input dense layer\n",
    "        self.W_Q = tf.keras.layers.Dense(config.n_head * config.d_head, kernel_initializer=kernel_initializer(), bias_initializer=bias_initializer())\n",
    "        self.W_K = tf.keras.layers.Dense(config.n_head * config.d_head, kernel_initializer=kernel_initializer(), bias_initializer=bias_initializer())\n",
    "        self.W_V = tf.keras.layers.Dense(config.n_head * config.d_head, kernel_initializer=kernel_initializer(), bias_initializer=bias_initializer())\n",
    "        # Scale Dot Product Attention class\n",
    "        self.attention = ScaleDotProductAttention(name=\"self_attention\")\n",
    "        # output dense layer\n",
    "        self.W_O = tf.keras.layers.Dense(config.d_model, kernel_initializer=kernel_initializer(), bias_initializer=bias_initializer())\n",
    "\n",
    "    def call(self, Q, K, V, attn_mask):\n",
    "        # reshape Q, K, V, attn_mask\n",
    "        batch_size = tf.shape(Q)[0]\n",
    "        Q_m = tf.transpose(tf.reshape(self.W_Q(Q), [batch_size, -1, self.n_head, self.d_head]), [0, 2, 1, 3])  # (bs, n_head, Q_len, d_head)\n",
    "        K_m = tf.transpose(tf.reshape(self.W_K(K), [batch_size, -1, self.n_head, self.d_head]), [0, 2, 1, 3])  # (bs, n_head, K_len, d_head)\n",
    "        V_m = tf.transpose(tf.reshape(self.W_V(V), [batch_size, -1, self.n_head, self.d_head]), [0, 2, 1, 3])  # (bs, n_head, K_len, d_head)\n",
    "        attn_mask_m = tf.expand_dims(attn_mask, axis=1)\n",
    "        # Scale Dot Product Attention with multi head Q, K, V, attn_mask\n",
    "        attn_out = self.attention(Q_m, K_m, V_m, attn_mask_m)  # (bs, n_head, Q_len, d_head)\n",
    "        # transpose and liner\n",
    "        attn_out_m = tf.transpose(attn_out, perm=[0, 2, 1, 3])  # (bs, Q_len, n_head, d_head)\n",
    "        attn_out = tf.reshape(attn_out_m, [batch_size, -1, config.n_head * config.d_head])  # (bs, Q_len, d_model)\n",
    "        attn_out = self.W_O(attn_out) # (bs, Q_len, d_model)\n",
    "\n",
    "        return attn_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionWiseFeedForward(tf.keras.layers.Layer):\n",
    "    def __init__(self, config, name=\"feed_forward\"):\n",
    "        super().__init__(name=name)\n",
    "\n",
    "        self.W_1 = tf.keras.layers.Dense(config.d_ff, activation=gelu, kernel_initializer=kernel_initializer(), bias_initializer=bias_initializer())\n",
    "        self.W_2 = tf.keras.layers.Dense(config.d_model, kernel_initializer=kernel_initializer(), bias_initializer=bias_initializer())\n",
    "\n",
    "    def call(self, inputs):\n",
    "        ff_val = self.W_2(self.W_1(inputs))\n",
    "        return ff_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, config, name=\"encoder_layer\"):\n",
    "        super().__init__(name=name)\n",
    "\n",
    "        self.self_attention = MultiHeadAttention(config)\n",
    "        self.norm1 = tf.keras.layers.LayerNormalization(epsilon=config.layernorm_epsilon)\n",
    "\n",
    "        self.ffn = PositionWiseFeedForward(config)\n",
    "        self.norm2 = tf.keras.layers.LayerNormalization(epsilon=config.layernorm_epsilon)\n",
    "\n",
    "        self.dropout = tf.keras.layers.Dropout(config.dropout)\n",
    " \n",
    "    def call(self, enc_embed, self_mask):\n",
    "        self_attn_val = self.self_attention(enc_embed, enc_embed, enc_embed, self_mask)\n",
    "        norm1_val = self.norm1(enc_embed + self.dropout(self_attn_val))\n",
    "\n",
    "        ffn_val = self.ffn(norm1_val)\n",
    "        enc_out = self.norm2(norm1_val + self.dropout(ffn_val))\n",
    "\n",
    "        return enc_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 레이어를 기반으로 한 BERT 구성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERT(tf.keras.layers.Layer):\n",
    "    def __init__(self, config, name=\"bert\"):\n",
    "        \n",
    "        super().__init__(name=name)\n",
    "\n",
    "        self.i_pad = config.i_pad\n",
    "        self.embedding = SharedEmbedding(config)\n",
    "        self.position = PositionalEmbedding(config)\n",
    "        self.segment = tf.keras.layers.Embedding(2, config.d_model, embeddings_initializer=kernel_initializer())\n",
    "        self.norm = tf.keras.layers.LayerNormalization(epsilon=config.layernorm_epsilon)\n",
    "        \n",
    "        self.encoder_layers = [EncoderLayer(config, name=f\"encoder_layer_{i}\") for i in range(config.n_layer)]\n",
    "\n",
    "        self.dropout = tf.keras.layers.Dropout(config.dropout)\n",
    "\n",
    "    def call(self, enc_tokens, segments):\n",
    "        enc_self_mask = get_pad_mask(enc_tokens, self.i_pad)\n",
    "\n",
    "        enc_embed = self.get_embedding(enc_tokens, segments)\n",
    "\n",
    "        enc_out = self.dropout(enc_embed)\n",
    "        for encoder_layer in self.encoder_layers:\n",
    "            enc_out = encoder_layer(enc_out, enc_self_mask)\n",
    "\n",
    "        logits_cls = enc_out[:,0]\n",
    "        logits_lm = enc_out\n",
    "        return logits_cls, logits_lm\n",
    "    \n",
    "    def get_embedding(self, tokens, segments):\n",
    "        embed = self.embedding(tokens) + self.position(tokens) + self.segment(segments)\n",
    "        embed = self.norm(embed)\n",
    "        return embed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BERT를 활용한 도전"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 추후 Pretrained BERT 모델과의 차이를 알기 위해, BERT 모델을 활용하여 학습시켜 본다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "#BERT 레이어에 Fully connected layer를 붙여, Kor용으로 finetune하기 위한 모델 클래스이다.\n",
    "class BERT4KorQuAD(tf.keras.Model):\n",
    "    def __init__(self, config):\n",
    "        super().__init__(name='BERT4KorQuAD')\n",
    "\n",
    "        self.bert = BERT(config)\n",
    "        self.dense = tf.keras.layers.Dense(2)\n",
    "    \n",
    "    def call(self, enc_tokens, segments):\n",
    "        logits_cls, logits_lm = self.bert(enc_tokens, segments)\n",
    "\n",
    "        hidden = self.dense(logits_lm) \n",
    "        start_logits, end_logits = tf.split(hidden, 2, axis=-1)  \n",
    "\n",
    "        start_logits = tf.squeeze(start_logits, axis=-1)\n",
    "        start_outputs = tf.keras.layers.Softmax(name=\"start\")(start_logits)\n",
    "\n",
    "        end_logits = tf.squeeze(end_logits, axis=-1)\n",
    "        end_outputs = tf.keras.layers.Softmax(name=\"end\")(end_logits)\n",
    "\n",
    "        return start_outputs, end_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'d_model': 256,\n",
       " 'n_head': 4,\n",
       " 'd_head': 64,\n",
       " 'dropout': 0.1,\n",
       " 'd_ff': 1024,\n",
       " 'layernorm_epsilon': 0.001,\n",
       " 'n_layer': 3,\n",
       " 'n_seq': 384,\n",
       " 'n_vocab': 32007,\n",
       " 'i_pad': 0}"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = Config({\"d_model\": 256, \"n_head\": 4, \"d_head\": 64, \"dropout\": 0.1, \"d_ff\": 1024, \"layernorm_epsilon\": 0.001, \"n_layer\": 3, \"n_seq\": 384, \"n_vocab\": 0, \"i_pad\": 0})\n",
    "config.n_vocab = len(vocab)\n",
    "config.i_pad = vocab.pad_id()\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_batch_size = 32 \n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((train_inputs, train_labels)).shuffle(10000).batch(bert_batch_size)\n",
    "vali_dataset = tf.data.Dataset.from_tensor_slices((vali_inputs, vali_labels)).batch(bert_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BERT4KorQuAD(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 학습시키기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, dataset, loss_fn, acc_fn, optimizer):\n",
    "    metric_start_loss = tf.keras.metrics.Mean(name='start_loss')\n",
    "    metric_end_loss = tf.keras.metrics.Mean(name='end_loss')\n",
    "    metric_start_acc = tf.keras.metrics.Mean(name='start_acc')\n",
    "    metric_end_acc = tf.keras.metrics.Mean(name='end_acc')\n",
    "\n",
    "    p_bar = tqdm(dataset)\n",
    "    for batch, ((enc_tokens, segments), (start_labels, end_labels)) in enumerate(p_bar):\n",
    "        with tf.GradientTape() as tape:\n",
    "            start_outputs, end_outputs = model(enc_tokens, segments)\n",
    "\n",
    "            start_loss = loss_fn(start_labels, start_outputs)\n",
    "            end_loss = loss_fn(end_labels, end_outputs)\n",
    "            loss = start_loss + end_loss\n",
    "\n",
    "            start_acc = acc_fn(start_labels, start_outputs)\n",
    "            end_acc = acc_fn(end_labels, end_outputs)\n",
    "        gradients = tape.gradient(loss, model.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "\n",
    "        metric_start_loss(start_loss)\n",
    "        metric_end_loss(end_loss)\n",
    "        metric_start_acc(start_acc)\n",
    "        metric_end_acc(end_acc)\n",
    "        if batch % 10 == 9:\n",
    "            p_bar.set_description(f'loss: {metric_start_loss.result():0.4f}, {metric_end_loss.result():0.4f}, acc: {metric_start_acc.result():0.4f}, {metric_end_acc.result():0.4f}')\n",
    "    p_bar.close()\n",
    "\n",
    "    return metric_start_loss.result(), metric_end_loss.result(), metric_start_acc.result(), metric_end_acc.result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_epoch(model, dataset, loss_fn, acc_fn):\n",
    "    metric_start_loss = tf.keras.metrics.Mean(name='start_loss')\n",
    "    metric_end_loss = tf.keras.metrics.Mean(name='end_loss')\n",
    "    metric_start_acc = tf.keras.metrics.Mean(name='start_acc')\n",
    "    metric_end_acc = tf.keras.metrics.Mean(name='end_acc')\n",
    "\n",
    "    for batch, ((enc_tokens, segments), (start_labels, end_labels)) in enumerate(dataset):\n",
    "        start_outputs, end_outputs = model(enc_tokens, segments)\n",
    "\n",
    "        start_loss = loss_fn(start_labels, start_outputs)\n",
    "        end_loss = loss_fn(end_labels, end_outputs)\n",
    "\n",
    "        start_acc = acc_fn(start_labels, start_outputs)\n",
    "        end_acc = acc_fn(end_labels, end_outputs)\n",
    "\n",
    "        metric_start_loss(start_loss)\n",
    "        metric_end_loss(end_loss)\n",
    "        metric_start_acc(start_acc)\n",
    "        metric_end_acc(end_acc)\n",
    "\n",
    "    return metric_start_loss.result(), metric_end_loss.result(), metric_start_acc.result(), metric_end_acc.result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4051895b74444eba3695f1b39ccb6d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "|          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval 0 >> loss: 3.5989, 4.1543, acc: 0.1487, 0.1289\n",
      "save best model\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c739b92d3d1440a3b6d94e400d27ca7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "|          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval 1 >> loss: 3.6529, 4.1514, acc: 0.1559, 0.1304\n",
      "save best model\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5f200e26689476081e3c63781fcf6e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "|          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval 2 >> loss: 3.6255, 4.1796, acc: 0.1626, 0.1413\n",
      "save best model\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac8c55a7ab7a4570adbd137f5247ee58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "|          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval 3 >> loss: 3.7802, 4.3512, acc: 0.1677, 0.1487\n",
      "save best model\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f6e8380b7fd4dec8a04c161a342b3e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "|          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval 4 >> loss: 4.1029, 4.6986, acc: 0.1508, 0.1426\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "910d2d79b9b84b6fabf3e6ba4fe9f22b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "|          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval 5 >> loss: 4.1676, 5.0859, acc: 0.1503, 0.1382\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53720ceb499a4ec7b69d1c9b0963452f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "|          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval 6 >> loss: 4.5432, 5.2922, acc: 0.1533, 0.1336\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1429105d33e04efb95780e0af41eade7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "|          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval 7 >> loss: 5.0988, 5.8246, acc: 0.1397, 0.1331\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a7318e93d3b497aa20fc2ba2d90ec1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "|          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval 8 >> loss: 5.3932, 6.2501, acc: 0.1396, 0.1282\n",
      "early stopping\n"
     ]
    }
   ],
   "source": [
    "loss_fn = tf.keras.losses.sparse_categorical_crossentropy\n",
    "acc_fn = tf.keras.metrics.sparse_categorical_accuracy\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=5e-4)\n",
    "\n",
    "best_acc = .0\n",
    "patience = 0\n",
    "for epoch in range(20):\n",
    "    train_epoch(model, train_dataset, loss_fn, acc_fn, optimizer)\n",
    "    start_loss, end_loss, start_acc, end_acc = eval_epoch(model, vali_dataset, loss_fn, acc_fn)\n",
    "    print(f'eval {epoch} >> loss: {start_loss:0.4f}, {end_loss:0.4f}, acc: {start_acc:0.4f}, {end_acc:0.4f}')\n",
    "    acc = start_acc + end_acc\n",
    "    if best_acc < acc:\n",
    "        patience = 0\n",
    "        best_acc = acc\n",
    "        model.save_weights(os.path.join(data_dir, \"korquad_bert_none_pretrain.hdf5\"))\n",
    "        print(f'save best model')\n",
    "    else:\n",
    "        patience += 1\n",
    "    if 5 <= patience:\n",
    "        print(f'early stopping')\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Pretrained model 로딩하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "## pretrained 모델을 로딩하여 model을 생성해본다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ssac23/SUBMIT_MISSION_GIT/ex19_BERT/Model/bert_pretrain_32000.hdf5\n",
      "Model: \"BERT4KorQuAD\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "bert (BERT)                  multiple                  10662400  \n",
      "_________________________________________________________________\n",
      "dense_75 (Dense)             multiple                  514       \n",
      "=================================================================\n",
      "Total params: 10,662,914\n",
      "Trainable params: 10,662,914\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "checkpoint_file = os.path.join(model_dir, 'bert_pretrain_32000.hdf5')\n",
    "\n",
    "print(checkpoint_file)loss_fn = tf.keras.losses.sparse_categorical_crossentropy\n",
    "acc_fn = tf.keras.metrics.sparse_categorical_accuracy\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=5e-4)\n",
    "\n",
    "best_acc = .0\n",
    "patience = 0\n",
    "for epoch in range(20):\n",
    "    train_epoch(model, train_dataset, loss_fn, acc_fn, optimizer)\n",
    "    start_loss, end_loss, start_acc, end_acc = eval_epoch(model, vali_dataset, loss_fn, acc_fn)\n",
    "    print(f'eval {epoch} >> loss: {start_loss:0.4f}, {end_loss:0.4f}, acc: {start_acc:0.4f}, {end_acc:0.4f}')\n",
    "    acc = start_acc + end_acc\n",
    "    if best_acc < acc:\n",
    "        patience = 0\n",
    "        best_acc = acc\n",
    "        model.save_weights(os.path.join(data_dir, \"korquad_bert_none_pretrain.hdf5\"))\n",
    "        print(f'save best model')\n",
    "    else:\n",
    "        patience += 1\n",
    "    if 5 <= patience:\n",
    "        print(f'early stopping')\n",
    "        break\n",
    "\n",
    "model = BERT4KorQuAD(config)\n",
    "\n",
    "#가중치 파일이 얌전히 그 위치에 있다묜\n",
    "if os.path.exists(checkpoint_file):\n",
    "    #pretrained model 을 로드하기 위해 먼저 모델이 생성되어 있어야 한다.\n",
    "    enc_tokens = np.random.randint(0, len(vocab), (4,10))\n",
    "    segments = np.random.randint(0, 2, (4,10))\n",
    "    model(enc_tokens, segments)\n",
    "    \n",
    "    model.load_weights(os.path.join(model_dir, \"bert_pretrain_32000.hdf5\"), by_name=True)\n",
    "    \n",
    "    model.summary()\n",
    "        \n",
    "else:\n",
    "    print(\"There is not pretrained-Model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pre-trained된 모델로 학습을 진행해본다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3824962c6794bf8a2560e120cc428f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "|          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval 0 >> loss: 4.0427, 4.6293, acc: 0.0751, 0.0544\n",
      "save best model\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed6b5d1352704d81a0d0ceca94632d31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "|          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval 1 >> loss: 4.0678, 4.6048, acc: 0.0804, 0.0630\n",
      "save best model\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c346c8a833554f0c911e1314b3668a9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "|          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval 2 >> loss: 3.8685, 4.3868, acc: 0.1222, 0.1002\n",
      "save best model\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f182b74b972d46e4b164bae84e505b90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "|          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval 3 >> loss: 3.7744, 4.3439, acc: 0.1378, 0.1283\n",
      "save best model\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86f388f489604ef992acd46c3b6cd1a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "|          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval 4 >> loss: 3.8352, 4.2843, acc: 0.1506, 0.1327\n",
      "save best model\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "119c62959b9c4220bd814e98cf41d5f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "|          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval 5 >> loss: 3.8439, 4.4189, acc: 0.1496, 0.1378\n",
      "save best model\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e11e5af5b44047eab93da73935ab9f82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "|          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval 6 >> loss: 4.1823, 4.8241, acc: 0.1375, 0.1366\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26af66328bc24c1d833741c91eb38bd8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "|          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval 7 >> loss: 4.5500, 5.0323, acc: 0.1297, 0.1269\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a5d9ea05e0342a49d43ccdd2662f2e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "|          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval 8 >> loss: 4.8428, 5.6985, acc: 0.1331, 0.1292\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8236ec2d55f244a2b08274a59403d8a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "|          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval 9 >> loss: 5.1873, 6.1955, acc: 0.1239, 0.1229\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36eeef689cbb4b0ab73b73b053d733f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "|          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval 10 >> loss: 5.4551, 6.5254, acc: 0.1194, 0.1225\n",
      "early stopping\n"
     ]
    }
   ],
   "source": [
    "loss_fn = tf.keras.losses.sparse_categorical_crossentropy\n",
    "acc_fn = tf.keras.metrics.sparse_categorical_accuracy\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=5e-4)\n",
    "\n",
    "best_acc = .0\n",
    "patience = 0\n",
    "for epoch in range(20):\n",
    "    train_epoch(model, train_dataset, loss_fn, acc_fn, optimizer)\n",
    "    start_loss, end_loss, start_acc, end_acc = eval_epoch(model, vali_dataset, loss_fn, acc_fn)\n",
    "    print(f'eval {epoch} >> loss: {start_loss:0.4f}, {end_loss:0.4f}, acc: {start_acc:0.4f}, {end_acc:0.4f}')\n",
    "    acc = start_acc + end_acc\n",
    "    if best_acc < acc:\n",
    "        patience = 0\n",
    "        best_acc = acc\n",
    "        model.save_weights(os.path.join(data_dir, \"korquad_bert_none_pretrain.hdf5\"))\n",
    "        print(f'save best model')\n",
    "    else:\n",
    "        patience += 1\n",
    "    if 5 <= patience:\n",
    "        print(f'early stopping')\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Inference 수행하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- pretrained 데이터를 활용하여 모델을 학습시켰고, 실제로 퀴즈 풀이 결과를 확인하여 학습 결과를 체크해 보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_predict(model, question, context):\n",
    "   \n",
    "    q_tokens = vocab.encode_as_pieces(question)[:args.max_query_length]\n",
    "    c_tokens = vocab.encode_as_pieces(context)[:args.max_seq_length - len(q_tokens) - 3]\n",
    "    tokens = ['[CLS]'] + q_tokens + ['[SEP]'] + c_tokens + ['[SEP]']\n",
    "    token_ids = [vocab.piece_to_id(token) for token in tokens]\n",
    "    segments = [0] * (len(q_tokens) + 2) + [1] * (len(c_tokens) + 1)\n",
    "\n",
    "    y_start, y_end = model(np.array([token_ids]), np.array([segments]))\n",
    "    # print(y_start, y_end)\n",
    "    y_start_idx = K.argmax(y_start, axis=-1)[0].numpy()\n",
    "    y_end_idx = K.argmax(y_end, axis=-1)[0].numpy()\n",
    "    answer_tokens = tokens[y_start_idx:y_end_idx + 1]\n",
    "\n",
    "    return vocab.decode_pieces(answer_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "질문 :  임종석이 여의도 농민 폭력 시위를 주도한 혐의로 지명수배 된 날은?\n",
      "지문 :  1989년 2월 15일 여의도 농민 폭력 시위를 주도한 혐의(폭력행위등처벌에관한법률위반)으로 지명수배되었다. 1989년 3월 12일 서울지방검찰청 공안부는 임종석의 사전구속영장을 발부받았다. 같은 해 6월 30일 평양축전에 임수경을 대표로 파견하여 국가보안법위반 혐의가 추가되었다. 경찰은 12월 18일~20일 사이 서울 경희대학교에서 임종석이 성명 발표를 추진하고 있다는 첩보를 입수했고, 12월 18일 오전 7시 40분 경 가스총과 전자봉으로 무장한 특공조 및 대공과 직원 12명 등 22명의 사복 경찰을 승용차 8대에 나누어 경희대학교에 투입했다. 1989년 12월 18일 오전 8시 15분 경 서울청량리경찰서는 호위 학생 5명과 함께 경희대학교 학생회관 건물 계단을 내려오는 임종석을 발견, 검거해 구속을 집행했다. 임종석은 청량리경찰서에서 약 1시간 동안 조사를 받은 뒤 오전 9시 50분 경 서울 장안동의 서울지방경찰청 공안분실로 인계되었다.\n",
      "정답 :  1989년 2월 15일\n",
      "예측 :  1989년 2월 15일 여의도 농민 폭력 시위를 주도한 혐의(폭력행위등처벌에관한법률위반)으로 지명수배되었다. 1989년 3월 12일 서울지방검찰청 공안부는 임종석의 사전구속영장을 발부받았다. 같은 해 6월 30일 평양축전에 임수경을 대표로 파견하여 국가보안법위반 혐의가 추가되었다. 경찰은 12월 18일 \n",
      "\n",
      "2\n",
      "질문 :  임종석이 여의도 농민 폭력 시위를 주도한 혐의로 지명수배된 연도는?\n",
      "지문 :  1989년 2월 15일 여의도 농민 폭력 시위를 주도한 혐의(폭력행위등처벌에관한법률위반)으로 지명수배되었다. 1989년 3월 12일 서울지방검찰청 공안부는 임종석의 사전구속영장을 발부받았다. 같은 해 6월 30일 평양축전에 임수경을 대표로 파견하여 국가보안법위반 혐의가 추가되었다. 경찰은 12월 18일~20일 사이 서울 경희대학교에서 임종석이 성명 발표를 추진하고 있다는 첩보를 입수했고, 12월 18일 오전 7시 40분 경 가스총과 전자봉으로 무장한 특공조 및 대공과 직원 12명 등 22명의 사복 경찰을 승용차 8대에 나누어 경희대학교에 투입했다. 1989년 12월 18일 오전 8시 15분 경 서울청량리경찰서는 호위 학생 5명과 함께 경희대학교 학생회관 건물 계단을 내려오는 임종석을 발견, 검거해 구속을 집행했다. 임종석은 청량리경찰서에서 약 1시간 동안 조사를 받은 뒤 오전 9시 50분 경 서울 장안동의 서울지방경찰청 공안분실로 인계되었다.\n",
      "정답 :  1989년\n",
      "예측 :  1989년 \n",
      "\n",
      "16\n",
      "질문 :  알렉산더 메이그스 헤이그의 생년월일은?\n",
      "지문 :  알렉산더 메이그스 헤이그 2세(영어: Alexander Meigs Haig, Jr., 1924년 12월 2일 ~ 2010년 2월 20일)는 미국의 국무 장관을 지낸 미국의 군인, 관료 및 정치인이다. 로널드 레이건 대통령 밑에서 국무장관을 지냈으며, 리처드 닉슨과 제럴드 포드 대통령 밑에서 백악관 비서실장을 지냈다. 또한 그는 미국 군대에서 2번째로 높은 직위인 미국 육군 부참모 총장과 나토 및 미국 군대의 유럽연합군 최고사령관이었다. 한국 전쟁 시절 더글러스 맥아더 유엔군 사령관의 참모로 직접 참전하였으며, 로널드 레이건 정부 출범당시 초대 국무장관직을 맡아 1980년대 대한민국과 미국의 관계를 조율해 왔다. 저서로 회고록 《경고:현실주의, 레이건과 외교 정책》(1984년 발간)이 있다.\n",
      "정답 :  1924년 12월 2일\n",
      "예측 :  2세(영어: Alexander Meigs Haig, Jr., 1924년 12월 2일 ~ 2010년 2월 20일 \n",
      "\n",
      "17\n",
      "질문 :  알렉산더 헤이그가 로널드 레이건 대통령 밑에서 맡은 직책은 무엇이었나?\n",
      "지문 :  알렉산더 메이그스 헤이그 2세(영어: Alexander Meigs Haig, Jr., 1924년 12월 2일 ~ 2010년 2월 20일)는 미국의 국무 장관을 지낸 미국의 군인, 관료 및 정치인이다. 로널드 레이건 대통령 밑에서 국무장관을 지냈으며, 리처드 닉슨과 제럴드 포드 대통령 밑에서 백악관 비서실장을 지냈다. 또한 그는 미국 군대에서 2번째로 높은 직위인 미국 육군 부참모 총장과 나토 및 미국 군대의 유럽연합군 최고사령관이었다. 한국 전쟁 시절 더글러스 맥아더 유엔군 사령관의 참모로 직접 참전하였으며, 로널드 레이건 정부 출범당시 초대 국무장관직을 맡아 1980년대 대한민국과 미국의 관계를 조율해 왔다. 저서로 회고록 《경고:현실주의, 레이건과 외교 정책》(1984년 발간)이 있다.\n",
      "정답 :  국무장관\n",
      "예측 :  국무장관 \n",
      "\n",
      "39\n",
      "질문 :  헤이그가 정계로 다시 돌아간 년도는?\n",
      "지문 :  그의 편에 헤이그는 지구촌의 논점들의 국내적 정치 노력들에 관해서만 근심한 레이건의 가까운 조언자들을 \"외교 정책의 아마추어\"로 묘사하였다. 1982년 6월 25일 결국적으로 온 그의 국무장관으로서 사임은 불가능한 상황이 된 것을 끝냈다. 헤이그는 개인적 생활로 돌아갔다가 1988년 대통령 선거를 위한 공화당 후보직을 안정시키는 시도를 하는 데 충분하게 정계로 돌아갔으나 후보직을 이기는 데 성원을 가지지 않았다. 그는 외교 정책 논쟁들에 연설자로서 활동적으로 남아있었으나 그의 전념은 정치에서 개인적 생활로 옮겨졌다. 그는 Worldwide Associates Inc.의 국제적 상담 회사에 의하여 기용되었고, 그 기구의 의장과 회장이 되었다.\n",
      "정답 :  1988년\n",
      "예측 :  1988년 \n",
      "\n",
      "40\n",
      "질문 :  하나님의 명령에 배를 만들고 가족과 짐승들을 배에 태워 홍수를 피한 사람은 누구인가?\n",
      "지문 :  노아는 하나님의 명령에 따라 배를 만들고 가족과 정결한 짐승 암수 일곱 마리씩, 부정한 짐승 암수 한 마리씩(혹은 두 마리씩; 사본에 따라 다름), 그리고 새 암수 일곱 마리씩을 싣고 밀어닥친 홍수를 피하였다. 모든 사람들이 타락한 생활에 빠져 있어 하나님이 홍수로 심판하려 할 때 홀로 바르게 살던 노아는 하나님의 특별한 계시로 홍수가 올 것을 미리 알게 된다. 그는 길이 300 규빗, 너비 50 규빗, 높이 30 규빗(고대의 1규빗은 팔꿈치에서 가운데 손가락끝까지의 길이로 약 45~46cm를 가리킴), 상 ·중 ·하 3층으로 된 방주를 만들어 8명의 가족과, 한 쌍씩의 여러 동물을 데리고 이 방주에 탄다. 대홍수를 만나 모든 생물(물고기 제외)이 전멸하고 말았지만, 이 방주에 탔던 노아의 가족과 동물들은 살아 남았다고 한다.〈창세기〉 6장 14~16절에 보면 길이 300규빗 (약 135m), 폭 50 규빗 (약 22.5m), 높이 30 규빗 (약 13.5m)인 이 배는 지붕과 문을 달고 배 안은 3층으로 만들어져 있었다. 선체(船體)는 고페르나무(잣나무)로 되고 안쪽에는 역청(아스팔트와 비슷한 성분)을 칠하여 굳혔다고 기록하고 있다.\n",
      "정답 :  노아\n",
      "예측 :  마리씩, 부정한 짐승 암수 한 마리씩(혹은 두 마리씩; 사본에 따라 다름), 그리고 새 암수 일곱 마리씩을 싣고 밀어닥친 홍수를 피하였다. 모든 사람들이 타락한 생활에 빠져 있어 하나님이 홍수로 심판하려 할 때 홀로 바르게 살던 노아는 하나님의 특별한 계시로 홍수가 올 것을 미리 알게 된다. 그는 길이 300 규빗, 너비 50 규빗, 높이 30 규빗(고대의 1규빗은 팔꿈치에서 가운데 손가락끝까지의 길이로 약 45~46cm를 가리킴), 상 ·중 ·하 3층으로 된 방주를 만들어 8명의 가족과, 한 쌍씩의 여러 동물을 데리고 이 방주에 탄다. 대홍수를 만나 모든 생물(물고기 제외)이 전멸하고 말았지만, 이 방주에 탔던 노아의 가족과 동물들은 살아 남았다고 한다.〈창세기〉 6장 14~16절에 보면 길이 300규 \n",
      "\n",
      "41\n",
      "질문 :  노아의 방주에 대해 기록하고있는 복음서는 무엇인가?\n",
      "지문 :  노아는 하나님의 명령에 따라 배를 만들고 가족과 정결한 짐승 암수 일곱 마리씩, 부정한 짐승 암수 한 마리씩(혹은 두 마리씩; 사본에 따라 다름), 그리고 새 암수 일곱 마리씩을 싣고 밀어닥친 홍수를 피하였다. 모든 사람들이 타락한 생활에 빠져 있어 하나님이 홍수로 심판하려 할 때 홀로 바르게 살던 노아는 하나님의 특별한 계시로 홍수가 올 것을 미리 알게 된다. 그는 길이 300 규빗, 너비 50 규빗, 높이 30 규빗(고대의 1규빗은 팔꿈치에서 가운데 손가락끝까지의 길이로 약 45~46cm를 가리킴), 상 ·중 ·하 3층으로 된 방주를 만들어 8명의 가족과, 한 쌍씩의 여러 동물을 데리고 이 방주에 탄다. 대홍수를 만나 모든 생물(물고기 제외)이 전멸하고 말았지만, 이 방주에 탔던 노아의 가족과 동물들은 살아 남았다고 한다.〈창세기〉 6장 14~16절에 보면 길이 300규빗 (약 135m), 폭 50 규빗 (약 22.5m), 높이 30 규빗 (약 13.5m)인 이 배는 지붕과 문을 달고 배 안은 3층으로 만들어져 있었다. 선체(船體)는 고페르나무(잣나무)로 되고 안쪽에는 역청(아스팔트와 비슷한 성분)을 칠하여 굳혔다고 기록하고 있다.\n",
      "정답 :  창세기\n",
      "예측 :  마리씩, 부정한 짐승 암수 한 마리씩(혹은 두 마리씩; 사본에 따라 다름), 그리고 새 암수 일곱 마리씩을 싣고 밀어닥친 홍수를 피하였다. 모든 사람들이 타락한 생활에 빠져 있어 하나님이 홍수로 심판하려 할 때 홀로 바르게 살던 노아는 하나님의 특별한 계시로 홍수가 올 것을 미리 알게 된다. 그는 길이 300 규빗, 너비 50 규빗, 높이 30 규빗(고대의 1규빗은 팔꿈치에서 가운데 손가락끝까지의 길이로 약 45~46cm를 가리킴), 상 ·중 ·하 3층으로 된 방주를 만들어 8명의 가족과, 한 쌍씩의 여러 동물을 데리고 이 방주에 탄다. 대홍수를 만나 모든 생물(물고기 제외)이 전멸하고 말았지만, 이 방주에 탔던 노아의 가족과 동물들은 살아 남았다고 한다.〈창세기〉 6장 14~16절에 보면 길이 300규빗 (약 135m), 폭 50 규빗 (약 22.5m), 높이 30 규빗 (약 13.5m \n",
      "\n",
      "43\n",
      "질문 :  노아는 누구의 명령에 따라 배를 만들고 가족과 동물들을 태웠는가?\n",
      "지문 :  노아는 하나님의 명령에 따라 배를 만들고 가족과 정결한 짐승 암수 일곱 마리씩, 부정한 짐승 암수 한 마리씩(혹은 두 마리씩; 사본에 따라 다름), 그리고 새 암수 일곱 마리씩을 싣고 밀어닥친 홍수를 피하였다. 모든 사람들이 타락한 생활에 빠져 있어 하나님이 홍수로 심판하려 할 때 홀로 바르게 살던 노아는 하나님의 특별한 계시로 홍수가 올 것을 미리 알게 된다. 그는 길이 300 규빗, 너비 50 규빗, 높이 30 규빗(고대의 1규빗은 팔꿈치에서 가운데 손가락끝까지의 길이로 약 45~46cm를 가리킴), 상 ·중 ·하 3층으로 된 방주를 만들어 8명의 가족과, 한 쌍씩의 여러 동물을 데리고 이 방주에 탄다. 대홍수를 만나 모든 생물(물고기 제외)이 전멸하고 말았지만, 이 방주에 탔던 노아의 가족과 동물들은 살아 남았다고 한다.〈창세기〉 6장 14~16절에 보면 길이 300규빗 (약 135m), 폭 50 규빗 (약 22.5m), 높이 30 규빗 (약 13.5m)인 이 배는 지붕과 문을 달고 배 안은 3층으로 만들어져 있었다. 선체(船體)는 고페르나무(잣나무)로 되고 안쪽에는 역청(아스팔트와 비슷한 성분)을 칠하여 굳혔다고 기록하고 있다.\n",
      "정답 :  하나님\n",
      "예측 :  마리씩; 사본에 따라 다름), 그리고 새 암수 일곱 마리씩을 싣고 밀어닥친 홍수를 피하였다. 모든 사람들이 타락한 생활에 빠져 있어 하나님이 홍수로 심판하려 할 때 홀로 바르게 살던 노아는 하나님의 특별한 계시로 홍수가 올 것을 미리 알게 된다. 그는 길이 300 규빗, 너비 50 규빗, 높이 30 규빗(고대의 1규빗은 팔꿈치에서 가운데 손가락끝까지의 길이로 약 45~46cm를 가리킴), 상 ·중 ·하 3층으로 된 방주를 만들어 8명의 가족과, 한 쌍씩의 여러 동물을 데리고 이 방주에 탄다. 대홍수를 만나 모든 생물(물고기 제외)이 전멸하고 말았지만, 이 방주에 탔던 노아의 가족과 동물들은 살아 남았다고 한다.〈창세기〉 6장 14~16절에 보면 길이 300규 \n",
      "\n",
      "56\n",
      "질문 :  제칠일안식교에서 비롯된 의사과학의 한 종류인 유사지질학의 이름은 무엇인가?\n",
      "지문 :  역사학과 과학의 발달이 더뎠던 고대사회에서는, 성경이 단순한 교리적인 부분 뿐 아니라 역사책으로서의 권위도 높았기에 노아의 방주를 역사적인 존재로서 다루고 있었다. 이는 제칠일안식교에서 비롯된 의사과학의 한 종류인 유사지질학인 홍수지질학과 같은 것에 영향을 주었으며, 과거 신학에서는 이러한 근본주의적 해석을 받아들여 역사와 사회적인 모든 부분에 있어 성경을 교과서로 채택할 것을 촉구했다. 이러한 홍수지질학을 주장했던 유사지질학자들은 성경에 나오는 노아의 홍수가 어딘가에 그 흔적이 남아 있을것이라고 주장하며 노아의 방주를 찾기 위한 노력을 했다고 주장한다. 이들은 같은 메소포타미아 지방의 신화인 이슬람교 경전이나 길가메쉬 서사시등의 신화를 들어서 이를 근거라고 주장하기도 했다. 그러나 이러한 전통적 근본주의적 시각은 과거에는 상당히 힘을 얻었으나, 역사학과 과학의 발달에 따라 힘을 잃게 되었고, 홍수지질학은 유사과학으로서 남게 되었다. 현대에는 뒤의 실존논란에서 다루는 것처럼 이러한 근본주의적 해석은 비과학적인 해석으로 여기는 것이 일반적이지만, 남침례교로 대표되는 극보수주의계열 기독교에서는 아직도 이것이 받아들여지고 있다.\n",
      "정답 :  홍수지질학\n",
      "예측 :  칠일안식교에서 비롯된 의사과학의 한 종류인 유사지질학인 홍수지질학과 같은 것에 영향을 주었으며, 과거 신학에서는 이러한 근본주의적 해석을 받아들여 역사와 사회적인 모든 부분에 있어 성경을 교과서로 채택할 것을 촉구했다. 이러한 홍수지질학을 주장했던 유사지질학자들은 성경에 나오는 노아의 홍수가 어딘가에 그 흔적이 남아 있을것이라고 주장하며 노아의 방주를 찾기 위한 노력을 했다고 주장한다. 이들은 같은 메소포타미아 지방의 신화인 이슬람교 경전이나 길가메쉬 서사시등의 신화를 \n",
      "\n",
      "64\n",
      "질문 :  한국에서 홍수지질학적 주장들을 내어 놓고 있는 집단은?\n",
      "지문 :  물론 노아의 방주가 신학과 신앙에서 중요한 영향을 차지하는 것은 사실이나, 현재 노아의 방주가 역사적으로 실존한다는 주장은 그 증거가 존재하지 않기에 관련 학계로부터 전혀 인정받지 못하고 있으며 그 실존과 안정성에 대한 수많은 논란이 있다. 한국창조과학회 등에서는 제칠일안식교를 기반으로 한 홍수지질학적 주장들을을 내어 놓고 있지만, 사실과 다른 근거들을 바탕으로 주장하므로 신뢰하기 힘든 것들이 전부라 할 수 있다. 그러므로 현재 노아의 방주가 실존한다는 주장은 그 증거가 존재하지 않기에 관련 학계로부터 전혀 인정받지 못하고 있다. 모든 과학관련 학계에서는 노아의 방주의 구조나 재질등이 실제로 존재할 수 없는 설화속 이야기라는 데에 동의하고 있다.\n",
      "정답 :  한국창조과학회\n",
      "예측 :  실존한다는 주장은 그 증거가 존재하지 않기에 관련 학계로부터 전혀 인정받지 못하고 있으며 그 실존과 안정성에 대한 수많은 논란이 있다. 한국창조과학회 등에서는 제칠일안식교를 \n",
      "\n",
      "66\n",
      "질문 :  2012년 중국에서 노아의 방주가 발견되었다는 보도를 한 방송사는 어디인가?\n",
      "지문 :  일반적으로 터키의 아라랏 산의 경우, 실제 성경 속에 등장하는 아라랏 산은 지금 아라랏이라 불리는 하나의 산이 아니라 당시 아라랏이라고 불리던 광대한 지역의 산들을 모두 가리키는 표현이라는 주장도 나와 있으며, 또한 목재로 만들어진 방주가 현재까지 남아있을 수는 없다는 비판도 받고 있다. 예를 들어, 1955년 프랑스의 탐험가인 Fernand Navarra가 발견한 목재 파편의 경우, 스페인의 임업 연구소에서 목재의 특성을 토대로 5000년 전의 것이라고 밝히긴 했으나 그 신빙성에 문제점이 있었고 후에 방사성 동위원소 측정법 등의 첨단 과학의 도움을 받은 5개 연구소에서 모두 기원 이후의 시기로 연대를 측정했다. 2009년 뿐 아니라 거의 수년에 한번씩 어디선가 노아의 방주를 발견했다는 주장들이 제시되었지만, 심지어 같은 창조과학을 주장하는 사람들에게조차 비판받을 정도였다. 노아의 방주가 다른 여러 지방에서 발견되었다는 주장이 있으나 너무나 다양한 지방(중국, 터키, 인도 등)에 걸쳐있고, 그 주장도 각각 제각각이므로 신빙성이 없다. 예를 들자면, 중국 BTV에서는 2012년에 중국에서 노아의 방주가 발견되었다는 보도를 하였는데, 이것은 창조과학회에서 주장하는 장소와는 전혀 다른곳이기도 하며, 화석화가 진행되지 않은 나무의 존재등으로 가짜임이 밝혀졌다. 때때로 일부 \"학자\"라 칭하는 사람들이 이를 찾기 위해 노력한다고 주장하지만, 이는 학계에서 유사지질학으로 평가되고 있다.\n",
      "정답 :  BTV\n",
      "예측 :  중국 BTV에서는 2012년에 중국에서 노아의 방주가 발견되었다는 보도를 하였는데, 이것은 창조과학회에서 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70\n",
      "질문 :  2012년 중국 BTV에서 노아의 방주가 발견되었다고 보도한 나라는?\n",
      "지문 :  일반적으로 터키의 아라랏 산의 경우, 실제 성경 속에 등장하는 아라랏 산은 지금 아라랏이라 불리는 하나의 산이 아니라 당시 아라랏이라고 불리던 광대한 지역의 산들을 모두 가리키는 표현이라는 주장도 나와 있으며, 또한 목재로 만들어진 방주가 현재까지 남아있을 수는 없다는 비판도 받고 있다. 예를 들어, 1955년 프랑스의 탐험가인 Fernand Navarra가 발견한 목재 파편의 경우, 스페인의 임업 연구소에서 목재의 특성을 토대로 5000년 전의 것이라고 밝히긴 했으나 그 신빙성에 문제점이 있었고 후에 방사성 동위원소 측정법 등의 첨단 과학의 도움을 받은 5개 연구소에서 모두 기원 이후의 시기로 연대를 측정했다. 2009년 뿐 아니라 거의 수년에 한번씩 어디선가 노아의 방주를 발견했다는 주장들이 제시되었지만, 심지어 같은 창조과학을 주장하는 사람들에게조차 비판받을 정도였다. 노아의 방주가 다른 여러 지방에서 발견되었다는 주장이 있으나 너무나 다양한 지방(중국, 터키, 인도 등)에 걸쳐있고, 그 주장도 각각 제각각이므로 신빙성이 없다. 예를 들자면, 중국 BTV에서는 2012년에 중국에서 노아의 방주가 발견되었다는 보도를 하였는데, 이것은 창조과학회에서 주장하는 장소와는 전혀 다른곳이기도 하며, 화석화가 진행되지 않은 나무의 존재등으로 가짜임이 밝혀졌다. 때때로 일부 \"학자\"라 칭하는 사람들이 이를 찾기 위해 노력한다고 주장하지만, 이는 학계에서 유사지질학으로 평가되고 있다.\n",
      "정답 :  중국\n",
      "예측 :  터키의 아라랏 산의 경우, 실제 성경 속에 등장하는 아라랏 산은 지금 아라랏이라 불리는 하나의 산이 아니라 당시 아라랏이라고 불리던 광대한 지역의 산들을 모두 가리키는 표현이라는 주장도 나와 있으며, 또한 목재로 만들어진 방주가 현재까지 남아있을 수는 없다는 비판도 받고 있다. 예를 들어, 1955년 프랑스의 탐험가인 Fernand Navarra가 발견한 목재 파편의 경우, 스페인의 임업 연구소에서 목재의 특성을 토대로 5000년 전의 것이라고 밝히긴 했으나 그 신빙성에 문제점이 있었고 후에 방사성 동위원소 측정법 등의 첨단 과학의 도움을 받은 5개 연구소에서 모두 기원 이후의 시기로 연대를 측정했다. 2009년 뿐 아니라 거의 수년에 한번씩 어디선가 노아의 방주를 발견했다는 주장들이 제시되었지만, 심지어 같은 창조과학을 주장하는 사람들에게조차 비판받을 정도였다. 노아의 방주가 다른 여러 지방에서 발견되었다는 주장이 있으나 너무나 다양한 지방(중국, 터키, 인도 등)에 걸쳐있고, 그 주장도 각각 제각각이므로 신빙성이 없다. 예를 들자면, 중국 BTV에서는 2012년에 중국에서 노아의 \n",
      "\n",
      "78\n",
      "질문 :  목재 선박의 배수량의 한계는 얼마인가?\n",
      "지문 :  창조과학회에서는 또한 노아의 방주가 안정적인 구조였다고 주장하지만, 이와는 달리 노아의 방주는 항해가 불가능한 설계에 가깝다. 실제로 창조과학에서 주장하는 방주의 크기와 철제 부품을 사용하지 않은 목재 선박 중에서 가장 큰 수준의 선박들을 비교하면 배수량이 두배 이상 차이난다. 그리고 목재 선박은 강도 상의 문제 때문에 통상 길이 100m, 배수량 2000톤 정도가 한계로 여겨져 왔다. 창조과학회에서는 노아의 방주의 안정성을 실험하기 위한 연구가 있다고 주장하기도 하나, 그 자체의 불합리성에 대한 비판을 받고 있으며, 관련 주요 연구자는 지질학 석사학위, 생물학 학사학위를 가진 초등학교 교사로서, 주류 학계의 학회나 저널 등에 발표한 적이 없으며 또한 정당한 피어 리뷰에 의해 검증받지 않았다.\n",
      "정답 :  2000톤\n",
      "예측 :  100m, 배수량 2000톤 \n",
      "\n",
      "80\n",
      "질문 :  목재 선박은 강도상의 문제로 통상 길이 몇m가 한계인가?\n",
      "지문 :  창조과학회에서는 또한 노아의 방주가 안정적인 구조였다고 주장하지만, 이와는 달리 노아의 방주는 항해가 불가능한 설계에 가깝다. 실제로 창조과학에서 주장하는 방주의 크기와 철제 부품을 사용하지 않은 목재 선박 중에서 가장 큰 수준의 선박들을 비교하면 배수량이 두배 이상 차이난다. 그리고 목재 선박은 강도 상의 문제 때문에 통상 길이 100m, 배수량 2000톤 정도가 한계로 여겨져 왔다. 창조과학회에서는 노아의 방주의 안정성을 실험하기 위한 연구가 있다고 주장하기도 하나, 그 자체의 불합리성에 대한 비판을 받고 있으며, 관련 주요 연구자는 지질학 석사학위, 생물학 학사학위를 가진 초등학교 교사로서, 주류 학계의 학회나 저널 등에 발표한 적이 없으며 또한 정당한 피어 리뷰에 의해 검증받지 않았다.\n",
      "정답 :  100m\n",
      "예측 :  100m, 배수량 2000톤 \n",
      "\n",
      "81\n",
      "질문 :  노아의 방주 안정성을 실험하기 위한 연구가 있다고 주장하는 단체는?\n",
      "지문 :  창조과학회에서는 또한 노아의 방주가 안정적인 구조였다고 주장하지만, 이와는 달리 노아의 방주는 항해가 불가능한 설계에 가깝다. 실제로 창조과학에서 주장하는 방주의 크기와 철제 부품을 사용하지 않은 목재 선박 중에서 가장 큰 수준의 선박들을 비교하면 배수량이 두배 이상 차이난다. 그리고 목재 선박은 강도 상의 문제 때문에 통상 길이 100m, 배수량 2000톤 정도가 한계로 여겨져 왔다. 창조과학회에서는 노아의 방주의 안정성을 실험하기 위한 연구가 있다고 주장하기도 하나, 그 자체의 불합리성에 대한 비판을 받고 있으며, 관련 주요 연구자는 지질학 석사학위, 생물학 학사학위를 가진 초등학교 교사로서, 주류 학계의 학회나 저널 등에 발표한 적이 없으며 또한 정당한 피어 리뷰에 의해 검증받지 않았다.\n",
      "정답 :  창조과학회\n",
      "예측 :  방주가 안정적인 구조였다고 주장하지만, 이와는 달리 노아의 방주는 항해가 불가능한 설계에 가깝다. 실제로 창조과학에서 주장하는 방주의 크기와 철제 부품을 사용하지 않은 목재 선박 중에서 가장 큰 수준의 선박들을 비교하면 배수량이 두배 이상 차이난다. 그리고 목재 선박은 강도 상의 문제 때문에 통상 길이 100m, 배수량 2000톤 정도가 한계로 여겨져 왔다. 창조과학회에서는 노아의 방주의 안정성을 실험하기 위한 연구가 있다고 주장하기도 하나, 그 자체의 불합리 \n",
      "\n",
      "93\n",
      "질문 :  하코다테 전쟁 시 반류마루의 함장의 이름은 무엇인가?\n",
      "지문 :  일련의 하코다테 전쟁은 적아 쌍방의 문서에 마쓰오카 바키치 함장의 능란한 조함 능력과 냉정한 지휘만이 기록되어 있다. 함포 사격으로 마쓰마에 성을 공격하여 엄호한 이후, 1869년 메이지 2년 3월 25일 미야코 만 해전에서는 폭풍우를 만나 요함과 헤어졌을 때에 만날 약속했던 하치노헤 항에서 대기하고 있었기 때문에 참전에는 이르지 못했다. 이 폭풍우 때도 “함장 마쓰오카 바키치는 배를 조정하는 명수로 로프 하나 손상되지 않았다”고 타고 있던 하야시 다다스가 남긴 바 있다. 이 귀로에서 신정부 군의 철갑함의 추격을 받았다. 기관 능력의 차이로 인한 속도차 때문에 도주가 불가능하다고 판단하고 맞장 공격을 하겠다고 전투 준비를 했지만, 철갑선의 사정거리에 들어간 순간에 순풍이 불기 시작하여 추격을 뿌리치고 하코다테로 돌아올 수 있었다.\n",
      "정답 :  마쓰오카 바키치\n",
      "예측 :  마쓰오카 바키치 함장의 능란한 조함 능력과 냉정한 지휘만이 기록되어 있다. 함포 사격으로 마쓰마에 성을 공격하여 엄호 \n",
      "\n",
      "95\n",
      "질문 :  반류마루가 미야코 만 해전당시 폭풍우를 만나 요함과 헤어졌을 때에 만날 약속하여 하치노헤 항에서 대기한 날짜는 언제인가?\n",
      "지문 :  일련의 하코다테 전쟁은 적아 쌍방의 문서에 마쓰오카 바키치 함장의 능란한 조함 능력과 냉정한 지휘만이 기록되어 있다. 함포 사격으로 마쓰마에 성을 공격하여 엄호한 이후, 1869년 메이지 2년 3월 25일 미야코 만 해전에서는 폭풍우를 만나 요함과 헤어졌을 때에 만날 약속했던 하치노헤 항에서 대기하고 있었기 때문에 참전에는 이르지 못했다. 이 폭풍우 때도 “함장 마쓰오카 바키치는 배를 조정하는 명수로 로프 하나 손상되지 않았다”고 타고 있던 하야시 다다스가 남긴 바 있다. 이 귀로에서 신정부 군의 철갑함의 추격을 받았다. 기관 능력의 차이로 인한 속도차 때문에 도주가 불가능하다고 판단하고 맞장 공격을 하겠다고 전투 준비를 했지만, 철갑선의 사정거리에 들어간 순간에 순풍이 불기 시작하여 추격을 뿌리치고 하코다테로 돌아올 수 있었다.\n",
      "정답 :  1869년 메이지 2년 3월 25일\n",
      "예측 :  1869년 메이지 2년 3월 25일 \n",
      "\n",
      "99\n",
      "질문 :  미야코 만 해전에서 아쓰오카 바키치 함장이 폭풍우를 만난 년도는?\n",
      "지문 :  일련의 하코다테 전쟁은 적아 쌍방의 문서에 마쓰오카 바키치 함장의 능란한 조함 능력과 냉정한 지휘만이 기록되어 있다. 함포 사격으로 마쓰마에 성을 공격하여 엄호한 이후, 1869년 메이지 2년 3월 25일 미야코 만 해전에서는 폭풍우를 만나 요함과 헤어졌을 때에 만날 약속했던 하치노헤 항에서 대기하고 있었기 때문에 참전에는 이르지 못했다. 이 폭풍우 때도 “함장 마쓰오카 바키치는 배를 조정하는 명수로 로프 하나 손상되지 않았다”고 타고 있던 하야시 다다스가 남긴 바 있다. 이 귀로에서 신정부 군의 철갑함의 추격을 받았다. 기관 능력의 차이로 인한 속도차 때문에 도주가 불가능하다고 판단하고 맞장 공격을 하겠다고 전투 준비를 했지만, 철갑선의 사정거리에 들어간 순간에 순풍이 불기 시작하여 추격을 뿌리치고 하코다테로 돌아올 수 있었다.\n",
      "정답 :  1869년\n",
      "예측 :  1869년 메이지 2년 \n",
      "\n",
      "맞은 정답 개수 :  86\n"
     ]
    }
   ],
   "source": [
    "dev_json = os.path.join(data_dir, \"korquad_dev.json\")\n",
    "\n",
    "with open(dev_json) as f:\n",
    "    \n",
    "    #총 정답 수를 확인하기 위해 변수를 적용하였다.\n",
    "    count = 100\n",
    "    \n",
    "    for i, line in enumerate(f):\n",
    "        data = json.loads(line)\n",
    "        question = vocab.decode_pieces(data['question'])\n",
    "        context = vocab.decode_pieces(data['context'])\n",
    "        answer = data['answer']\n",
    "        answer_predict = do_predict(model, question, context)\n",
    "        if answer in answer_predict:\n",
    "            print(i)\n",
    "            print(\"질문 : \", question)\n",
    "            print(\"지문 : \", context)\n",
    "            print(\"정답 : \", answer)\n",
    "            print(\"예측 : \", answer_predict, \"\\n\")\n",
    "            \n",
    "            if answer != answer_predict:\n",
    "                count -= 1\n",
    "            \n",
    "        if 100 < i:\n",
    "            print(\"맞은 정답 개수 : \", count)\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - 학습된 모델에게 100개의 질문을 하고, 실제 정답과 예측 정답을 비교해 보았다.     \n",
    "> - 변수를 통해 확인한 결과, __총 100개의 질문 중 맞은 정답 개수는 86개이다.__       \n",
    "> - 단, 이는 단순히 정답 != 정답 예측 일 경우만 센 것으로, 예측이 정답보다 포괄적인 경우(ex)정답이 1869년이고, 예측이 1869년 메이지 2년인 경우 1869년==메이지 2년이므로 넓은 범위의 정답으로 볼 수 있겠다.) 를 제외한 것이므로, 실질적인 정답률은 이보다 높을 수 있겠다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 시각화하여 확인해보기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - 히스토리 저장 안하고 돌려서 다시 돌리는 중 ㅠㅠ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "start_loss, end_loss, start_acc, end_acc\n",
    "# training result\n",
    "plt.figure(figsize=(16, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(start_loss, 'b-', label='start_loss')\n",
    "plt.plot(end_loss, 'r--', label='end_loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(start_acc, 'g-', label='start_acc')\n",
    "plt.plot(end_acc, 'k--', label='end_acc')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiffel",
   "language": "python",
   "name": "aiffel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
